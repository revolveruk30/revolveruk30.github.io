<html>
<title>SANS Notes</title>
<meta name="robots" content="noindex,nofollow" />

<link rel="stylesheet" href="w2.css">
<link rel="stylesheet" href="w3-theme-black.css">
<link rel="stylesheet" href="roboto.css">
<link rel="stylesheet" href="font-awesome.min.css">
<head>
<style>



html, body {
-webkit-user-select: none;
-moz-user-select: none;
-ms-user-select: none;
user-select: none;
oncontextmenu="return false";
onselectstart="return false";
ondragstart="return false";
background-color: #f0f0f0;
}


* {
  box-sizing: border-box;
}

.w3-sidebar {
	z-index: 3;
	width: 345px;
	top: 30px;
	bottom: 0;
	height: inherit;
	text-align: justify
	height: 100%;
	background-color: #f0f0f0;
	position: fixed;
	overflow: auto;
	line-height: 0.2
}
.w3-searchbox {
	height: 25%;
	width: 110%;
	left:405px;
	top: 23px;
	overflow: hidden;
	background-color: black;
	position: fixed;
	z-index: 1;
	line-height: 2;
 margin-top: -7px; 

}

.w3-topbar {
	width: 100%;
	height:5%;
	background-color: black;
	position: fixed;
	top: -3px;
	overflow: hidden;

	
}


#myInput {
  background-repeat: no-repeat;
  width: 40%;
  border: 1px solid #ddd;
 margin-top: 20px; 
 margin-bottom: 12px;
  margin-left: 95px;
  text-align: center;
 font-family: "Roboto", sans-serif

}

#keywords {
  background-repeat: no-repeat;
  width: 20%;
  border: 1px solid #ddd;
  border: 1px solid #ddd;
  margin-bottom: 12px;
  margin-left: 120px;

 text-align: center;
 font-family: "Roboto", sans-serif

}
#myUL {
  list-style-type: none;
  padding: 0;
  text-align: justify;
  margin-top: 150px;
  width: 70%;
}

#myUL li a {
  margin-top: -1px; 
  padding: 8px;
  text-decoration: none;
  font-size: 14px;
  color: black;
  display: block
}

}
</style>
</head>

<body>
<!-- Topbar -->
<div class="w3-topbar"></div>

<!-- Sidebar -->
<nav class="w3-sidebar w3-bar-block w3-collapse w3-small w3-theme-l5" id="mySidebar">

<BR>
<p>
<BR>
<center><H3>SANS COURSE NOTES</H3></center>
<BR>
<p>
<BR>
<a class=" w3-button w3-hover-blue" href="sec401.html">SEC 401 - Security Essentials</a>
<a class="w3-button w3-hover-blue" href="sec450.html">SEC 450 - Blue Team Fundamentals</a>
<a class="w3-button w3-hover-green" href="for500.html">FOR 500 - Windows Forensic Analysis</a>
<a class="w3-button w3-hover-blue" href="sec502.html">SEC 502 - Perimeter Protection</a>
<a class="w3-button w3-hover-red" href="sec504.html">SEC 504 - Hacker Tools</a>
<a class="w3-button w3-hover-blue" href="sec506.html">SEC 506 - Linux/Unix Security</a>
<a class="w3-button w3-hover-green" href="for508.html">FOR 508 - Incident Response Forensics</a>
<a class="w3-button w3-hover-blue" href="sec511.html">SEC 511 - Continuous Monitoring</a>
<a class="w3-button w3-hover-blue" href="sec555.html">SEC 555 - SIEM with Tactical Analytics</a>
<P>
<center>
<a class="w3-button" href="standards.html">Security Standards</a><br>
<a class="w3-button" href="books.html">Security Books</a><br>
<a class="w3-button" href="tools.html">Security Tools</a>
</center>
</nav>
<nav class="w3-searchbox" id="searchbox">

<input type="text" id="myInput" onkeyup="myFunction()" placeholder="Filter Paragraph by Keyword" title="Search">
<form method="GET" onsubmit="myHilitor.apply(hilite.value); return false;">
<input type="text" id="keywords" size="20" name="hilite" placeholder="Highlight Multiple Keywords">
<input type="submit" value="Apply">
<input type="button" value="Remove" onclick="myHilitor.remove();">
</span>
</form>

</nav>


<div class="w3-main w3-theme-l5" style="margin-left:300px"> 
<div class="w3-row w3-padding-64">               
<h2 class="w3-text-teal"></h2>
<div id="playground">


<center>





<ul id="myUL">

  <p>  Linux/Unix Security, Hal Pomeranz<p>
<li><a href="#">As far as the "how" goes, there are a large number of Unix security "recipes" out there on the Internet for many, many different operating systems. The free CIS hardening "benchmarks" at CISecurity.org are a good place to start if you want to "translate" the guidance in this course into actionable commands on different Unix and Linux variants.


<li><a href="#">What are the most important things I can do to secure my Unix-like system? The biggest component is to present as small a target as possible by reducing the number of potential vulnerabilities on your system. This process starts from the moment you install the system with the smallest, most "minimal" OS image that will allow you to successfully run your application. Patches need to be applied to the base OS image and then maintained for the lifetime of the machine.


<li><a href="#">Perhaps the most important task is to disable services that are not being used so that you're not exposed to as yet unknown vulnerabilities in these services. Sometimes you can't completely disable a service, but you can use a host-based firewall or some other IP-based access control to restrict which machines may have access to that service.


<li><a href="#">Memory attacks of various sorts- buffer overflows, heap overflows, return to libc attacks, format string attacks, and so on, have become an enormously popular mechanism for gaining remote access to systems.


<li><a href="#">A buffer overflow exploit attempts to write past the end of the allocated string buffer and clobber the return execution address. If successful, the program will not return to the original calling function but will instead jump to some other malicious instruction created by the attacker. Attackers overflow buffers by sending the program long input strings (via input prompts in the program, environment variables, Remote Procedure Calls, etc.). These attacks succeed because many programmers don't always check the length of the input they receive and happily accept long inputs which can be used to overwrite memory in this fashion.


<li><a href="#">The classic buffer overflow attacker constructs a string which contains a bunch of "no-op" instructions for padding, then the nasty code, then the evil instruction address repeated many, many times. The instruction address is repeated because the attacker can never really be exactly certain where the return pointer is relative to the buffer they're overflowing.


<li><a href="#">The most common evil instruction set is a variant of the exec () system call which replaces the current process with a new process. The "classic" buffer overflow described in Aleph's paper uses exec (/bin/ sh) , which gives the attacker an interactive shell, but newer attacks will typically run a more complicated script that downloads rootkits and possibly additional exploit code to compromise the system and make it into part of a botnet for DDoS attacks or spamming.


<li><a href="#">Well-behaved programs should never execute code in any other portion of memory, e.g., from the stack or heap areas. The "fix" for most buffer overflow attacks is to simply modify the kernel so that attempting to execute an instruction in the stack area causes the program to abort. This behavior is generally referred to as stack protection.


<li><a href="#">Stack protection is enabled by default in Linux since kernel version 2.6.8- at least on 64-bit CPUs. noexec user stack enables stack protection. The noexec user stack log setting causes the kernel to log to syslog when it shuts down an application that is violating the stack protection rules.


<li><a href="#">While kernel-based stack protection can stop buffer overflows in any application running on the machine, work is also being done to develop compilers that produce executable code that is resistant to buffer overflows. This is of particular interest on platforms where kernel-based stack protection is not available but is also used in conjunction with normal kernel-based stack protection.


<li><a href="#">The idea is that an additional data value called a "canary " (as an analogy to the canaries coal miners use to warn them of toxic gasses) is inserted into the normal stack frame between the return address pointer and the subroutine variables area. Any classic buffer overflow exploit that overflows the data area and writes downward to the return address pointer is also going to overwrite the canary value (although this is not true in a format string attack). As part of the normal subroutine exit sequence, the canary value is checked. If the value changes, then the program simply aborts itself rather than returning to the memory address in the (probably corrupted) return address pointer.


<li><a href="#">• Disable services that are not absolutely necessary for accomplishing your mission. The best way to prevent an attacker from exploiting a vulnerability on your system is to not be running the vulnerable software in the first place.


<li><a href="#">• Keep up-to-date on security announcements and patches from your vendor. Don't get victimized by vulnerabilities that have been known for months. Most vendors have security alert mailing lists you can subscribe to for timely updates.


<li><a href="#">• Use strong encryption to protect the data flowing between client and server. Strong encryption is also the only real protection you have from session hijacking.


<li><a href="#">• Only grant access to systems that have a legitimate need to access a given service.


<li><a href="#">• As much as possible, try to run " one app per server" so that a vulnerability in one service doesn't end up compromising another. Some applications also allow administrators to run them in a restricted environment via the chroot () system call (more on this later in the curriculum).


<li><a href="#">• Where possible, avoid running applications with root privilege, so that if an attacker does get access to the system, there are some limits on what they can do. Kernel-based privilege restriction solutions like SELinux are also helpful here.


<li><a href="#">From a security perspective, you want to choose the smallest set of OS programs possible for your application because each piece of software you add might have a security vulnerability that could be used to exploit your system. It also turns out that smaller OS images are also a win from a system stability perspective (less that could go wrong) and from a performance perspective (less stuff is running and consuming system resources, and the system boots much quicker if it doesn't have to start dozens of different daemons at boot time).


<li><a href="#">There are lots of different classes of potentially dangerous services out there:


<li><a href="#">• File sharing via NFS and Samba is certainly dangerous for Internet servers and should be disabled.


<li><a href="#">• NIS and other RPC-based services are also incompatible with security in hostile, unprotected network environments. Most of the recent worms and other Unix exploits seem to have been targeting vulnerable RPC services.


<li><a href="#">• Apache is fine if you're a Web server, but if you're not then why run httpd? Disable printing if you don't print, SNMP if you're not monitoring your machines this way, etc.


<li><a href="#">• I find many of the "convenience" features like power management and volume managers to be more annoying than helpful. Volume managers also make it easy for users and attackers with physical access to compromise your system with tools and set-UID programs brought in on USB and DVD.


<li><a href="#">• If you only manage the system over the network, do you need that GUI login running on your machine's console (and the X server that goes with it)?


<li><a href="#">You can simply disable the 25/tcp listener on all of the Unix systems in your environment that are not acting as mail servers. It's possible that you could have 25/tcp shut down on all Unix machines because none of them act as mail servers. This would be a huge security win since it protects you from future potential e-mail-based exploits and worms.


<li><a href="#">Having stopped a service, remove its configuration files: • inetd/xinetd config files and directories • NFS, automounter config files • Other server configs, server home dirs • Useless crontab files


<li><a href="#">The idea behind removing these files is to make auditing your system easier. If any of these files reappear on your system you will know that something is far wrong with your machine. Also, removing the configuration file for a service will often prevent that service from starting normally if somebody (accidentally or on purpose) re-enables that service.


<li><a href="#">Session hijacking is an attack where the bad guy takes over a network session already in progress. If the attacker manages to take over your session after you've logged into a server and become root, then the attacker has suddenly achieved a root shell without ever guessing a single password! Naive users may be completely unaware that this has happened, just writing the event off to a brief network outage that caused their session to lock up or be reset.


<li><a href="#">Encryption not only protects the transmitted data but also makes session hijacking essentially impossible. In order to hijack an encrypted session, the attacker would have to determine the session key being used to encrypt the data between client and server. For a decent cryptosystem, this should be "computationally infeasible".


<li><a href="#">If you look at most of the remote SSH exploits, the vulnerabilities have occurred in the very early stages of the connection process. In particular, a goodly number of the attacks have been due to vulnerabilities in things like the OpenSSL encryption libraries or the Kerberos and S/Key libraries used during authentication, rather than in the SSH code base per se. Hence, these have been vulnerabilities that are largely out of the control of the SSH developers.


<li><a href="#">Host based firewalls can be used to restrict what network traffic the system will accept, further reducing the number of entry points for external attackers. As network-layer perimeter security mechanisms become increasingly porous to attack, implementing filtering on individual systems becomes more and more important.


<li><a href="#">Network layer filtering not only is the first line of defense against external attackers but is also the place where you prevent obviously bogus traffic from reaching your hosts. For example, spoofed traffic (traffic from "outside" that is sourced from an internal IP address) can be dropped, along with traffic from reserved address spaces (the loopback network 127.0.0.0/8 and the RFC1918 network space). Source-routed traffic, maliciously fragmented traffic, and directed broadcasts can also be shut down.


<li><a href="#">The loopback interface is the only place you should be seeing net 127.0.0.0/8 traffic. So, once we've created rules to pass the loopback traffic, we can add a rule to drop any other traffic trying to reach the box that purports to come from this network ("- s " to specify source address). This is an example of what's usually referred to as an "anti-spoofing" filter.


<li><a href="#">You could sit on the console of the system entering all of these iptables commands by hand. The risk, however, is that you make a typo, or forget to add a rule or make some other trivial error that causes your firewall to fail. A much better approach would be to create a script file with all of your iptables commands. When you want to make a change, all you have to do is tweak the script and then re-run it. You can also run the same script on multiple systems to have a consistent policy.


<li><a href="#">IP Tables is capable of limiting both the number of connections and the bit rate on those connections in both the inbound and the outbound direction. IP Tables can do network address translation and even other types of packet mangling inline.


<li><a href="#">One common scenario is deploying backdoors into already compromised systems. An attacker who breaks root on your machine probably doesn't want to go through whatever hassle was required to break root initially. Besides the original root compromise may have been "noisy" enough that the attack was detected, and the hole closed. However, if the administrator fails to detect the backdoor left behind by the attacker, then the attacker still has free access to the system.


<li><a href="#">The typical rootkit will deliver Trojan versions of ls, find, dir and any other command that an administrator might use to detect the hidden files. In many cases, the Trojaned binaries will reference a configuration file that lists the files and directories that should be hidden. Sometimes the malicious binaries will ignore files and directories that contain a particular string somewhere in the file or directory name.


<li><a href="#">Rootkits also want to hide running processes (like the DDoS daemons and the rootkits’ packet sniffer) from the administrator. Rootkits will contain a Trojaned version of ps which hides certain processes-either specific processes or those listed in a configuration file. Similarly, the attacker doesn't want their processes to be stopped by the admin. The kill, p kill, and kill all programs are "fixed" so that they wouldn't actually kill any of the attackers' processes.


<li><a href="#">netstat can be used to detect network connections in progress. Typical rootkits install a new net stat that not only hides the attackers' backdoor connections but also hides connections between the DDoS daemon running on the system and the master controller for the daemon. Similarly, the rootkit will contain replacement Syslog agents that do not log the attacker's activity.


<li><a href="#">When you get around to wanting to close the holes in your system, your best bet is to simply re-install from scratch and then close the holes on a "virgin" system. Who knows, you might have missed a back-door on the old OS image that would allow the attacker to ·re-establish access if you put the machine back into production without rebuilding. Reinstalling from backups may be tricky because you can't be certain exactly when your system was compromised.


<li><a href="#">In the Internet security arms race, though, the growing use of malicious kernel modules gives the attacker the ability to subvert the system kernel and globally change the behavior of all applications running on the system (including the integrity checking tools that the administrator relies on for alerts). Without taking the system offline and booting off a "known good" kernel it may be impossible to detect a sophisticated kernel exploit of this type.


<li><a href="#">AIDE works by initially creating a database of information about files on your system along with checksums it computes on the contents of these files. Files are added to this database based on a configuration file created by the administrator. The database for a machine should be created as soon as the machine is installed and before it gets connected to a production network where it might be compromised.


<li><a href="#">While it's likely that some of your systems will get broken into at some point in time, this is hopefully a fairly rare occurrence. The other 364 days out of the year, AIDE is really good at letting you know when your local administrative staff makes mistakes-either installing patches and clobbering files that they shouldn't or making configuration file updates that they shouldn't. AIDE's greatest long-term value to an organization may be its usefulness as a change control and configuration management tool.


<li><a href="#">AIDE's default is to run only the MDS algorithm against files. This is so that integrity checks (which might look at 10-20K files on a given system) don't bog down the machine too much. However, it is prudent to identify "critical" files on the system and monitor such files with multiple checksum algorithms as a special case.


<li><a href="#">Certain files and directories should always be checked. These include:


<li><a href="#">• Directories like / , /usr, and /var shouldn't change under normal operation (nobody should be adding new files and subdirectories immediately under any of these top-level directories).


<li><a href="#">• Keep an eye on root's dot-files-- . rhosts, . shosts, .profile, etc. The .ssh directory for root is very important to watch (especially the authorized_ keys file).


<li><a href="#">• Always watch configuration files in / etc. You need to avoid files like syslogd . pid and named . pid, though, which changes all the time. Ditto for files like mnttab and share tab which are generated from other configuration files at boot time.


<li><a href="#">• Keep an eye on your crontabs- you don't want anybody adding jobs without your say-so!


<li><a href="#">• Your kernel executable file and/or directory (typically something like /unix or /kernel or /bsd, etc.) including the directory that holds your loadable kernel modules


<li><a href="#">Critical files include:


<li><a href="#">• System shells (sh, csh, ksh, bash, ... )


<li><a href="#">• Daemons (inetd, syslogd, sshd, ... )


<li><a href="#">• Authentication (login, su, passwd, ... )


<li><a href="#">• Forensic tools (ls, ps, net stat, ifconfig, ... )


<li><a href="#">It's vital that you watch all bin and lib directories on your system. On most Unix machines this is a surprisingly large collection of directories including not only /usr /bin and /usr /1 ib, but also / sbin and /usr / sbin and /usr / libexec.


<li><a href="#">l think the "critical" files on your system are files that are likely to be modified by an attacker with a rootkit, including your standard forensic tools (if config, net stat, ps, etc.) and your login programs, daemons, and Unix shells. You might also want to watch important libraries like libc more closely than other files.


<li><a href="#">It's pretty well understood that an attacker with physical access can find a way to get root privileges on a machine. Rebooting into single-user mode, booting off of OS media, and even the old "corrupt the root file system" trick all require one or more reboots of the machine, however. So, it's a good idea to keep an eye on your system logs for suspicious reboots.


<li><a href="#">Booting off of OS media generally puts you into the system install program, but there's usually an option for dropping out to a shell prompt. This is effectively a root shell, albeit in the limited environment used by the install program. However, once at this shell, the user on the console can mount the local disk drives from the machine and have full root access. For administrators, the easiest thing to do at this point is to blank the password field for the root account in /etc/shadow and reboot normally.


<li><a href="#">Setting a boot loader password means that the system will require the user on the console to enter that password before any "special" boot commands can be used- like booting from CD-ROM, or even booting into single-user mode.


<li><a href="#">Even if you get this right, though, somebody with physical access to your system can just rip the disk drives out of your machine and mount them up on some other system that doesn't have these sorts of protections. On the other hand, you'd probably notice if this happened to one of your machines, so at least you'd know you bad a problem.


<li><a href="#">It is possible to set a BIOS password that must be entered as soon as the system powers on. The problem is that a BIOS password generally prevents the system from rebooting automatically. BIOS passwords can be helpful on laptops and other personal machines but are generally not advisable on server-type machines.


<li><a href="#">The question with these boot loader passwords is what password to use. Some sites use the system root password as the boot loader password, but this is actually a bad idea. One problem is that boot loader passwords are often stored insecurely on the system (sometimes in clear text form in configuration files). The other problem is that when a site updates their root passwords, they tend to forget to update the boot loader password.


<li><a href="#">Experts agree that the best policy is to force users to log in under an unprivileged account and then use su or sudo to get root access. This provides maximum audit trail and also forces attackers to compromise two accounts to "get to root."


<li><a href="#">Of course, in an emergency, it may be necessary to log in as root on the system console to save the system. However, root logins should be restricted to this console device only (and ideally the console is locked up in a secure data center).


<li><a href="#">Sudo allows the administrator to define a limited set of commands that a given user is allowed to run with privilege- usually as root, although Sudo allows the administrator to define other alternate users that the commands will run as. Each time the user uses Sudo to execute a command, logging data is produced so that the administrator has a complete audit trail in case the user makes a mistake.


<li><a href="#">When the user wants to run a command with privilege, they execute that command via the sudo program (e.g., "s udo cat /etc/ shadow"). Sudo prompts the user for their own password to verify the user's identity. The user never needs to know the superuser password for the system.


<li><a href="#">If the user had to enter their password every time, they ran a command via Sudo, it would be a huge hassle. So, what Sudo actually does is prompt the user for their password only on the first command. As long as the user keeps using Sudo to execute commands, Sudo "remembers" that the user entered their password correctly and doesn't prompt again.


<li><a href="#">Sudo's audit trail only works if the users religiously run the sudo program to execute all commands. However, it's a common tendency for frustrated users to simply run "sudo /bin/ sh" or "sudo /bin/ su" in order to get a root shell. At this point, any commands they type will not be logged by Sudo.


<li><a href="#">chroot () is a Unix system call that allows a process to give up access to all but a small portion of the file system. This enables programmers to create processes which run in a captive environment and therefore reduce many of the security risks to applications that have to face "hostile" networks- like the Internet.


<li><a href="#">When a process calls chroot () , it specifies a directory that the process will chroot () into. As far as the calling process is concerned, this directory becomes the root of the Unix file system for that process and the process is only able to access files from the chroot () ed directory and below.


<li><a href="#">One of the primary uses for chroot () is to run networked services in captive environments so that security holes in these services can't be exploited against the entire machine. Typically, these are complex services like FTP, Web servers, and DNS servers or services which are insecure in other ways. In the case of a buffer overflow attack or another remote exploit, even if the attacker gets access to the machine remotely, they won't be able to "see" the entire file system to plant their back-doors.


<li><a href="#">The problem with running applications in a chroot () ed environment is that the environment itself is often difficult to set up initially. Remember that the process is completely trapped in the chroot () ed directory- all binaries, shared libraries, system devices, configuration files, etc. must be properly configured by the administrator in the chroot () ed hierarchy before the application can be run.


<li><a href="#">It's not uncommon to find applications which are so deeply intertwined in the operating system that it's effectively impossible to run them in a chroot () ed environment. These sorts of applications should then be allowed to run by themselves on "sacrificial" machines where any security breaches can be more easily contained.


<li><a href="#">Newer operating systems are starting to implement even more granular process rights restrictions in the kernel, for example, the SELinux hooks in newer Linux kernels and the Privileges functionality in Solaris 10 and later. With this sort of functionality, you can define down to the level of individual files what objects in the operating system a given process may read, write, or execute. Fine-grained control over other system calls is also included. Perhaps if you develop a restrictive enough "white list" privilege model for a given process, then the chroot () call wouldn't be required at all. The difficulty with these fine-grained kernel controls is that they can be extremely complicated to configure.


<li><a href="#">SELinux is a very fine-grained set of access controls implemented in a kernel module. lt actually covers several different types of functionality:


<li><a href="#">Multi-level Security (MLS)/Multi-Category Security (MCS) - These sorts of security controls are typica1ly required at high-security sites that need to rigidly partition different categories of data (unclassified, classified, secret, top secret, etc.) on their networks. Outside of these kinds of environments, however, this level of access control is not widely used or needed.


<li><a href="#">Role-Based Access Control (RBAC}- One historic problem with the Unix security model has been "all or nothing" administrative access via the root account. RBAC is an attempt to address this deficiency by allowing sites to assign specific aspects of administrative privilege to a number of different roles. The end game would be to completely disable the root account and just assign people to specific roles based on their job function.


<li><a href="#">Type Enforcement (TE)- Type Enforcement is essentially an application "whitelisting" facility. Type Enforcement policies attempt to specify exactly which components of the operating system (files and directories, devices, sockets, etc.) a given application needs to interact with and what level of access the application needs (read access, write access, etc.).


<li><a href="#">The goal is to prevent an application that has been compromised by an attacker from misbehaving in ways that would allow the attacker to compromise the larger systems. So, Type Enforcement is really an "application isolation" strategy, similar to chroot ().


<li><a href="#">Most sites only implement SELinux Type Enforcement on certain critical processes and rely on normal Unix permissions to control access for interactive user sessions.


<li><a href="#">Because DNS is so critical for the operation of individual networks and the Internet as a whole, it's also a popular target for denial-of-service type attacks. Aside from DoS danger to your own infrastructure, badly configured DNS servers also provide attackers with an opportunity to "amplify" their attacks against other targets.


<li><a href="#">Your DNS database contains information about all of the machines in your organization. In particular, machine names and other information (HINFO and TXT records) may help an attacker locate machines which are most critical to the functioning of your organization or which can be easily targeted for attack. Generally, the outside world needs to know very little information about your network. At a minimum, you need to advertise hostnames and IP addresses of a limited set of "public" servers: name servers, e-mail servers, Web and FTP servers, etc.


<li><a href="#">Generally, each organization runs one master DNS server and one or more slave servers for redundancy. Periodically, the slaves must contact the master and download any updates to the local DNS database-this is referred to as a zone transfer. By default, nameservers running BIND allow any remote system to perform a zone transfer- whether that system is a legitimate name server for that domain or not. Zone transfers can even be requested from the slave name servers for your domains.


<li><a href="#">Attackers often attempt zone transfers in order to gather information about your local network. If they succeed, then they have instantly gotten all of the information about your internal hosts and networks with very little effort.


<li><a href="#">Split-horizon DNS is a DNS configuration where an organization presents one set of DNS information to external organizations and reserves a second, separate set of DNS information for internal use. This is generally done by maintaining two different collections of name servers: an "external" set which publishes the limited amount of DNS information that external organizations need to interact with your company, and an "internal" set which holds your complete, rich set of DNS information.


<li><a href="#">When your internal name servers wish to resolve external host names, they must contact root name servers and name servers at other Internet-connected sites. This can open up your internal name servers to attack from the outside. For this reason, many organizations that run split-horizon DNS also employ a sort of DNS proxying (slave forwarding name servers) to "hide" their internal name servers completely from the outside world.


<li><a href="#">The basic idea behind DNSSEC is reasonably straightforward:


<li><a href="#">• You generate a key pair and use it to sign your zones.


<li><a href="#">• You pass your public key back up the DNS chain to the owner of your TLD- for example, if we're sysiphus . com, then we give a copy of our key to the registry for .com


<li><a href="#">• The TLD uses DS (Delegation Signer) records to publish your public key (actually the key fingerprint) and then signs those records with its key.


<li><a href="#">• Similarly, the root zone maintainers use DS records for all of the TLDs and sign those keys with the key for the root zone.


<li><a href="#">• Everybody manually downloads the key for the root zone from central authority and verifies the key using something like a PGP signature.


<li><a href="#">Once this infrastructure is in place, then you should be able to verify DNS responses because there will be a "chain of trust" from the root of the DNS hierarchy. Attackers will be unable to spoofDNS responses unless they manage to steal the private key for some zone (so we'll need to rigorously protect those keys).


<li><a href="#">There end up being two different types of keys running around when you start using DNSSEC. First, there are the Zone Signing Keys (ZSK). These are the keys that are actually used to sign your zone files. But these are also the keys that you should recycle every 30 days.


<li><a href="#">So, the recommended strategy is to also create a Key Signing Key (KSK). As the name implies, you use the KSK to sign your ZSKs. You pass the public portion of the KSK up to your TLD registrar and that's what gets signed and put into OS records in the TLD.


<li><a href="#">SSL is based on public/private key encryption. Each server that wants to support SSL communications needs a public/private key pair. Browsers expect that the server's public key has been signed by a recognized certificate authority (CA)- this signed public key is referred to as a server certificate.


<li><a href="#">At its simplest, mod_ security is a pattern matching engine that allows you to match "signatures" of various kinds of malicious web traffic. You can also extend these rulesets to do more complicated checks using the Lua scripting language.


<li><a href="#">mod_security is deeply embedded in Apache via the Apache API and can filter not only the incoming HTTP request headers, but can also do deep content inspection (including uploaded fi le data), and even scan outgoing content from the web server to make sure you're not accidentally emitting information you shouldn't like PII and PCI


<li><a href="#">mod_security comes with a bundled set of rules which are called the "Core Rules". This is a fairly extensive set of mod security rules that have been developed over time to detect common sorts of malicious traffic and known exploits. They're also a good overview of the kinds of functionality available in mod_ security, and serve as an example of how you can write your own rules.


<li><a href="#">The file systems can be conceptualized as a "five layer" model:


<li><a href="#">• Physical Layer: The physical drive or device and the partitions on it. Sectors are the smallest unit of storage addressable by the disk controller.


<li><a href="#">• File System Layer: Contains all the configuration and management data associated with the file systems in each partition on the disk.


<li><a href="#">• The File Name Layer (AKA Human interface Layer) is responsible for mapping human-readable file names to metadata addresses.


<li><a href="#">• Metadata Layer: Contains all of the data structures that are responsible for the definition and delineation of files.


<li><a href="#">• Data Layer: Contains the actual data units of disk storage-commonly referred to as blocks in Unix file systems.


<li><a href="#">When a file system is created in a logical partition, a data structure is created at the beginning of the partition to define the attributes of the file system that resides there. For Unix file systems, this data structure is called a superblock. The superblock contains basic file system information including items like the file system type, block size, the number of blocks and inodes in the file system, the number of unallocated blocks and inodes, and so on.


<li><a href="#">The data layer is where the binary information is actually stored on disk. The smallest storage unit addressable by the disk device is a sector which is usually 512 bytes. However, to improve VO performance, EXT file systems will normally perform reads/writes in 4K chunks called blocks.


<li><a href="#">When writing a large file that spans multiple blocks, the file system will tend to allocate consecutive blocks where possible. This will increase the read efficiency because the file system can "read ahead" in large swaths. But this tendency also turns out to be useful when we're trying to recover deleted data. lf you can locate a suspicious string in the middle of a "deleted" block of data, you may be able to recover the entire deleted fi le by capturing the blocks immediately before and after the "interesting" block.


<li><a href="#">All file systems have structures that are used to describe or represent files . The metadata layer contains these structures. They are called different things in different file systems, but in the Unix world, they are known as inodes (which is a contraction of "index nodes").


<li><a href="#">An inode contains descriptive information such as timestamps, access controls or permissions, file owner's user id, and the file 's size--everything you're used to seeing in the output of" 1 s - 1" except for the file name. An inode also has pointers to the data blocks that make up the contents of the file.


<li><a href="#">The Unix operating system tracks files using the inode number and the device numbers associated with the disk partition that holds the file. But human beings don't find a series of numbers convenient for naming files, so some interface layer between humans and machines is necessary. The Human interface, or File Name Layer, contains special file system objects whose purpose is to associate human-readable file names with the inode numbers used by the OS. The "special objects" are what we call directories.


<li><a href="#">Directories are simply special files that associate file names with inodes. In the traditional Unix file systems, a directory "file" is just a sequential list of file names along with their corresponding inode. When you list a directory, you are basically just dumping the contents of the directory "file".


<li><a href="#">Evidence seizure generally occurs during the incident response phase where you must verify the incident, but you also begin your work to collect volatile and non-volatile data. Data that is volatile is lost if the system is adjusted prior to the collecting of that data, a memory dump of a process that contains key LP addresses of the attacker or subject. Non-volatile data is a hard drive that is powered off, static CD-ROMs.


<li><a href="#">Investigation and analysis occur when the investigator takes what is collected and analyzes it to form a clear picture of the incident. This analysis uses tools and techniques that require data recovery, piecing together the puzzle of what happened, and forming a timeline of events.


<li><a href="#">Reporting your results becomes the most important step. Without accurate reporting, the investigator often finds himself unable to find anyone willing to prosecute his case or take action. Without action, why perform the investigation? Reporting is key.


<li><a href="#">Image acquisition is the process of creating true bit images of the disks and removable media that may be associated with the system in question. It is an artform unto itself, albeit an easy one to master. Once these images have been acquired, the original evidence (system disk) can be locked in a container for safe keeping.


<li><a href="#">You will conduct your investigation against these images, performing media analysis. Examining the images for small pieces of evidence that will ultimately help you to reconstruct what happened in the past on a system. The two final pieces are the ones that are most often overlooked. The creation of an accurate and effective incident report, and incorporating any lessons learned back into the security processes and policies of the organization.


<li><a href="#">Much of the work involved in incident handling and forensic investigations can, and should be done ahead of time. These proactive measures will help you every step of the way when actually responding and investigating an incident. Having plans, call lists, response policies, an adequate detection infrastructure, and a trusted set of tools may ultimately make the difference between a successful response/investigation and one that is botched.


<li><a href="#">Step 1. Create "Case File". In general, describe the system you are analyzing. Where did you acquire the system? What is/was it used for? What is the configuration of the system (OS, network)? Include any other information you feel may be necessary to perform the investigation.


<li><a href="#">Step 2. Validate the Compromise. Once you have been notified of a suspected incident and have opened a case file, it is wise to work to validate that a system has actually been compromised. There will be numerous incidents where the compromise wasn't really a compromise after all- and there's the incident response team, all psyched up and nowhere to go.


<li><a href="#">Memory analysis can be enormously useful in an investigation. Since memory is analyzed on a different machine from the compromised system, it is less prone to interference from the attacker. Memory analysis may be the only way to obtain encryption keys necessary to unlock protected file systems.


<li><a href="#">Step 3. Collect Evidence. Evidence is defined as anything that can be collected from the system under investigation. lt does not necessarily have to be an image. It could include process information, network connections, log files, and user information.


<li><a href="#">Computer evidence is very volatile. You have to be very careful about completely understanding which evidence to gather and in what order. 1n some cases, gathering one piece of evidence will accidentally modify another.


<li><a href="#">Collecting evidence according to the order of volatility is a de-facto-standard approach. The idea is simple: some data on a system is more volatile le than other data. You should work to collect the most volatile data first. In cases where you feel there may be a "tie", then collect the most important evidence first.


<li><a href="#">Undoubtedly, memory is the most volatile evidence on a system, followed by swap space. Swap exists on a system's media but is constantly changing. You have no guarantee what state swap will be in once the system is powered off, so you should gather it separately.


<li><a href="#">Network connections are important. What if the subject had a print queue or was in the middle of a secure shell session while you powered down?


<li><a href="#">Running processes should also be gathered to testify as to the state of the system. Perhaps during your media analysis phase, you determine that the system scheduler had been Trojaned and had a sniffer wiretap wrapped into it. You now can check and see if that process was running at the time of seizure.


<li><a href="#">Evidence may exist in disk blocks that are no longer allocated to files. As a result of their unallocated state, these disk blocks may be reused at any time. lt would be a shame if the collection of one set of evidence (i.e. collecting physical memory) were to cause the destruction of other evidence that might reside in these blocks. Therefore, it is important to create files that hold evidence on some disk other than the disks of the victim system.


<li><a href="#">You may be able to physically remove the storage from the machine and connect it to a forensic disk duplicator, which would be the fastest copying option. Or you could connect the disk to another machine, being careful that the system you're plugging the disk into doesn't auto-mount the disk and change its state. If you're unable to remove the storage, you could boot the system using a Linux forensic distro like Paladin and image the disk that way.


<li><a href="#">dd is a utility that reads input files block by block. If you specify a disk device, you can capture fi le system metadata. This includes unallocated blocks that could contain deleted fi le data. This data will be missed if you use a logical file system collection tool like tar.


<li><a href="#">dcfldd is a modified version of the dd tool that will provide for updates as well as provide the ability to performing hashing on the raw data that it is collecting (rather than having to collect the data and then run md5sum on it separately). It works and is implemented just like the normal dd tool but with two extra options.


<li><a href="#">In order to start working with our disk images, we need a tool to examine the image and tell us where the partition boundaries are. The tool mrnls from the Sleuthkit (TSK) is useful in determining which partitions are located on a physical disk, the size, and the location in the physical disk image.


<li><a href="#">The timeline is usually the bedrock of an investigation. Everything revolves around it. Often, the investigator will have an idea of the window of time in which the compromise occurred once basic evidence has been obtained and analyzed or log fi le analysis has been performed. The timing of events- when files were accessed, changed, modified will directly point to the events that occurred on the system.


<li><a href="#">In terms of a timeline of events, we can learn a lot by looking at the MAC times associated with files. MAC stands for modification, access, and change. These times are recorded in the inode for each file and directory. The modification time tells us when a file was last modified. The access time tells us when a file was last accessed. The (metadata) change time records the last time that the contents of an inode were written. The inode contains information such as permissions and ownerships.


<li><a href="#">While MAC times are very useful in forensic investigations, be very careful. MAC times can be modified quite easily. Using the debugfs command, any one of these can be set to an appropriate time so as to fool the investigator.


<li><a href="#">Step 4. Create a Timeline . Analyze Timeline. The first step in making a timeline is to collect the MAC time data from all of the partitions in your image. The second step is to take the data in the body file that has just been created ( or a subset of it) and sort/format it.


<li><a href="#">Analyze the timeline to quickly identify: • When the OS was installed, updated, and last booted • Newly created files and directories (rootkit locations) • Recently replaced binaries (trojaned programs) • Altered bootscripts, password files, or other system files (backdoors)


<li><a href="#">Step 5: Analyze Disk Image : During media analysis, you will perform many different tasks. While it would be too difficult to list every action here, some of the actions that are recommended are: 1. Examine file system for modification to operating system software or configuration 2. Examine file system for backdoors, check for setuid and setgid files 3. Examine file system for any sign of a sniffer program 4. Shell history files 5. Show start-up files and processes


<li><a href="#">Now that we have our disk mounted, the next step is to gather basic information about the host. This data includes items like the name of the host, the OS version, its lP address, etc. This information will end up in your final report but is also important for analyzing the system.


<li><a href="#">Generally, attackers will be looking to set up backdoors to allow them to access the system. This means either setting up standard account access for themselves or running processes that give them a back door.


<li><a href="#">First, validate the passwd and shadow files for extraneous or mangled accounts, odd defaults shells and the like. Attackers will often create extra accounts with a UID 0, or enable blocked administrative accounts in an attempt to leave behind an easy backdoor. Another common target these days is the authorized keys file that holds the public half of identity certificates used to access the system remotely via SSH. Look for new or modified unit files in the systemd configuration directories.


<li><a href="#">Be sure to review the contents of your logs and the command history of any user accounts that may have been involved in the incident. Look for any hidden directories that begin with a".", some results will be valid directories others may not. You need to take a look at each of these and validate them.


<li><a href="#">More often than not, attackers will hide trojan rootkits in the / dev / directory. This is because there are so many files listed there. They have names like sdz 1 to sdz 9 so it can be hard to spot the files that do not belong.


<li><a href="#">Have any of the binaries in the file system been modified or created recently? Do any of them appear to have been "back-dated"? A good, hard look at the MAC times of binaries can tell you a lot about what has occurred on the system.


<li><a href="#">If a file is deleted, the contents (data blocks) are not overwritten immediately. The data still exists on disk and can be recovered until the free space is re-allocated by the OS and overwritten. You might think that the lifespan of deleted data is short, and that storage space that has been freed is used again quickly. This isn't necessarily the case. ln fact, because of the inode and disk block allocation algorithms, and the size of modem disk drives, this sort of collision occurs infrequently. The bottom line is that we can usually recover most (if not all) of a file even though it has been deleted.


<li><a href="#">Sometimes string searching can be the best mechanism to zero in on certain data of interest to your investigation. For example, if you suspect a particular piece of malware, there may be embedded strings that you can look for to detect the presence of the malware on your system.


<li><a href="#">Step 6. Create Incident Report. Reporting is not entirely a technical aspect of computer forensics, but it is probably the most important step of the forensic process. Most reporting is done to individuals who may not be educated in computer hardware, networking topics, or computer crime law. You need to ensure that your reporting clearly explains the evidence you found, the techniques you used and defines everything that is technical.


<li><a href="#">Step 7. Apply Lessons Learned. Every incident is an opportunity to learn about security and its application within our organization. It may be that the lesson learned is that new policies are needed. It may be that a policy was ignored. It could also be the case that there was little the organization could do, in which case the lessons learned would revolve around better incident handling. Make absolutely sure that your organization learns from these lapses.
</div>


<script>
function myFunction() {
    var input, filter, ul, li, a, i, txtValue;
    input = document.getElementById("myInput");
    filter = input.value.toUpperCase();
    ul = document.getElementById("myUL");
    li = ul.getElementsByTagName("li");
    for (i = 0; i < li.length; i++) {
        a = li[i].getElementsByTagName("a")[0];
        txtValue = a.textContent || a.innerText;
        if (txtValue.toUpperCase().indexOf(filter) > -1) {
            li[i].style.display = "";
        } else {
            li[i].style.display = "none";
        }
    }
}
</script>

<script src="hilitor.js"></script>
<script>
var myHilitor = new Hilitor("content"); // id of the element to parse
// myHilitor.setBreakRegExp(new RegExp('[^\\w\' -]+', "g")); // expanded to include spaces
myHilitor.apply();
</script>


<script>

  window.addEventListener("DOMContentLoaded", function(e) {
    var myHilitor2 = new Hilitor("playground");
    myHilitor2.setMatchType("left");
    document.getElementById("keywords").addEventListener("keyup", function(e) {
      myHilitor2.apply(this.value);
    }, false);
  }, false);

</script>

<script>
document.addEventListener("contextmenu", function(event){
event.preventDefault();
}, false);
</script>




</html>
