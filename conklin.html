<html>
<title>NOTES</title>
<meta charset="UTF-8">
<meta name="robots" content="noindex,nofollow" />
<link rel="stylesheet" href="w3.css">
<link rel="stylesheet" href="w3-theme-black.css">
<script>
document.addEventListener("contextmenu", function(event){
event.preventDefault();
}, false);
</script>

<body>
<!-- Sidebar -->
<nav class="w3-sidebar w3-bar-block w3-collapse w3-small w3-theme-l5" id="mySidebar">
<BR>
<BR>
<p>
<a class="w3-button w3-hover-black" href="anderson.html"><u>Security Engineering, Ross Anderson</u></a><br>
<a class="w3-button w3-hover-black" href="bishop.html"><u>Introduction to Computer Security, Matt Bishop</u></a><br>
<a class="w3-button w3-hover-black" href="bellovin.html"><u>Thinking About Security, Steven Bellovin</u></a><br>
<a class="w3-button w3-hover-black" href="iracf.html"><u>Incident Response & Computer Forensics, Luttgens, Pepe, Mandia</u></a><br>
<a class="w3-button w3-hover-black" href="conklin.html"><u>Computer Security Principles, Conklin, White</u></a><br>


</nav>
<nav class="w3-searchbox" id="searchbox">
<input type="text" id="myInput" size="3" onkeyup="myFunction()" placeholder="Filter Standard by Keyword" title="Search">
<form method="GET" onsubmit="myHilitor.apply(hilite.value); return false;">
<input type="text" id="keywords" size="10" name="hilite" placeholder="Highlight Keywords">  
<input type="submit" value="Apply">
<input type="button" value="Remove" onclick="myHilitor.remove();">
</span>
</form>
</nav>
<div class="w3-main w3-theme-l5" style="margin-left:300px"> 
<div class="w3-row w3-padding-64">               
<h2 class="w3-text-teal"></h2>
<div id="playground">
<center>
<ul id="myUL">
Computer Security Principles, Conklin, White
<P>
<li><a href="#">Security Trends

<li><a href="#">The security emphasis has shifted from the computer to the information being processed. Information security is defined by the information being protected from unauthorized access or alteration and yet is available to authorized individuals when required.

<li><a href="#">Today, computer equipment is inexpensive compared to the value of the data processed by the computer. Now the high-value item is not the machine, but the information that it stores and processes. This has fundamentally changed the focus of computer security from what it was in the early years.

<li><a href="#">Electronic crime can take a number of different forms, but the ones we will examine here fall into two basic categories: crimes in which the computer was the target, and incidents in which a computer was used to perpetrate the act.

<li><a href="#">One of the most effective measures security professionals can take to address attacks on their computer systems and networks is to ensure that all software is up to date in terms of vendor- released patches. Many of the outbreaks of viruses and worms would have been much less severe if everybody had applied security updates and patches when they were released.

<li><a href="#">Advanced Persistent Threats . Advanced refers to the use of advanced techniques, such as spear phishing, as a vector into a target. Persistent refers to the attacker's goal of establishing a long-term, hidden position on a system. Many APTs can go on for years without being noticed. Threat refers to the other objective: exploitation. If an adversary invests the resources to achieve an APT attack, they are doing it for some form of long-term advantage. APTs are not a specific type of attack, but rather the new means by which highly resourced adversaries target systems.

<li><a href="#">There are a number of ways that we can break down the various threats. One way to categorize them is to separate threats that come from outside of the organization from those that are internal. Another is to look at the various levels of sophistication of the attacks, from those by "script kiddies" to those by "elite hackers." A third is to examine the level of organization of the various threats, from unstructured threats to highly structured threats.

<li><a href="#">The act of deliberately accessing computer systems and networks without authorization is generally referred to as hacking, with individuals who conduct this activity being referred to as hackers. The term hacking also applies to the act of exceeding one's authority in a system.

<li><a href="#">Intruders are, if nothing else, extremely patient, since the process to gain access to a system takes persistence and dogged determination. The attacker will conduct many pre-attack activities in order to obtain the information needed to determine which attack will most likely be successful.

<li><a href="#">Generally, attacks by an individual or even a small group of attackers fall into the unstructured threat category. Attacks at this level generally are conducted over short periods of time (lasting at most a few months), do not involve a large number of individuals, have little financial backing, and are accomplished by insiders or outsiders who do not seek collusion with insiders.

<li><a href="#">At the low end technically are what are generally referred to as script kiddies, individuals who do not have the technical expertise to develop scripts or discover new vulnerabilities in software but who have just enough understanding of computer systems to be able to download and run scripts that others have developed. It is undoubtedly the fastest growing group and the vast majority of the "unfriendly" activity occurring on the Internet is probably carried out by these individuals.

<li><a href="#">At the next level are those people who are capable of writing scripts to exploit known vulnerabilities. These individuals are much more technically competent than script kiddies and account for an estimated 8 to 12 percent of malicious Internet activity. At the top end of this spectrum are those highly technical individuals, often referred to as elite hackers, who not only have the ability to write scripts that exploit vulnerabilities but also are capable of discovering new vulnerabilities. This group is the smallest of the lot, however, and is responsible for, at most, only 1 to 2 percent of intrusive activity.

<li><a href="#">It is generally acknowledged by security professionals that insiders are more dangerous in many respects than outside intruders. The reason for this is simple-insiders have the access and knowledge necessary to cause immediate damage to an organization. Attacks by insiders are often the result of employees who have become disgruntled with their organization and are looking for ways to disrupt operations.

<li><a href="#">Attacks by criminal organizations usually fall into the structured threat category, which is characterized by a greater amount of planning, a longer period of time to conduct the activity, more financial backing to accomplish it, and possibly corruption of, or collusion with, insiders.

<li><a href="#">Many nations today have developed to some extent the capability to conduct information warfare. There are several definitions for information warfare, but a simple one is that it is warfare conducted against the information and information processing equipment used by an adversary.

<li><a href="#">Information warfare falls into the highly structured threat category. This type of threat is characterized by a much longer period of preparation (years is not uncommon), tremendous financial backing, and a large and organized group of attackers. The threat may include attempts not only to subvert insiders but also to plant individuals inside of a potential target in advance of a planned attack.

<li><a href="#">Water, electricity, oil and gas refineries and distribution, banking and finance, telecommunications-all fall into the category of critical infrastructures for a nation. Critical infrastructures are those whose loss would have severe repercussions on the nation. With countries relying so heavily on these infrastructures, it is inevitable that they will be viewed as valid targets during conflict.

<li><a href="#">In light of the revelation that a pure state of security is not achievable in the binary sense, the focus has shifted to one of risk management. Today, the question is how much risk your system is exposed to, and from what sources.

<li><a href="#">The first step an administrator can take to reduce possible attacks is to ensure that all patches for the operating system and applications are installed. Many security problems that we read about, such as viruses and worms, exploit known vulnerabilities for which patches exist.

<li><a href="#">The second step an administrator can take is system hardening, which involves limiting the services that are running on the system. Only using those services that are absolutely needed does two things: it limits the possible avenues of attack (those services with vulnerabilities that can be exploited), and it reduces the number of services the administrator has to worry about patching in the first place.

<li><a href="#">There are three major considerations when securing a system:

<li><a href="#">Correctness . Ensuring that a system is fully up to date, with all patches installed and proper security controls in place; this goes a long way toward minimizing risk. Correctness begins with a secure development lifecycle, continues through patching and hardening, and culminates in operations.

<li><a href="#">Isolation . Protecting a system from unauthorized use, by means of access control and physical security. Isolation begins with infrastructure, continues with access control, and includes the use of cryptography.

<li><a href="#">Obfuscation . Making it difficult for an adversary to know when they have succeeded. Whether accomplished by obscurity, randomization, or obfuscation, increasing the workload of an attacker makes it more difficult for them to succeed in their attack.

<li><a href="#">General Security Concepts

<li><a href="#">A hacker was once considered an individual who understood the technical aspects of computer operating systems and networks. expertise. Today, primarily as a result of the media, the term is used more often to refer to individuals who attempt to gain unauthorized access to computer systems or networks.

<li><a href="#">Computer security entails the methods used to ensure that a system is secure. Subjects such as authentication and access controls must be addressed in broad terms of computer security.

<li><a href="#">Network security to refer to the protection of the multiple computers and other devices that are connected together. Information security and information assurance, which place the focus of the security process not on the hardware and software being used but on the data that is processed by them. The common press and many professionals have settled on cybersecurity as the term to describe the field.

<li><a href="#">The goal of computer security has been threefold: confidentiality, integrity, and availability-the "CIA" of security. The purpose of confidentiality is to ensure that only those individuals who have the authority to view a piece of information may do so. No unauthorized individual should ever be able to view data they are not entitled to access. Integrity is a related concept but deals with the generation and modification of data. Only authorized individuals should ever be able to create or change (or delete) information. The goal of availability is to ensure that the data, or the system itself, is available for use when the authorized user wants it.

<li><a href="#">As a result of the increased use of networks for commerce, two additional security goals have been added to the original three in the CIA of security. Authentication attempts to ensure that an individual is who they claim to be. Related to this is non-repudiation, or accountability, which deals with the ability to verify that a message has been sent and received and that the sender can be identified and verified.

<li><a href="#">Recent emphasis on systems assurance has raised the potential inclusion of the term auditability, which refers to whether a control can be verified to be functioning properly. In security, it is imperative that we can track actions to ensure what has or has not been done.

<li><a href="#">Our security equation thus becomes: Protection = Prevention + (Detection + Response) This is known as the operational model of computer security. Every security technique and technology falls into at least one of the three elements of the equation.

<li><a href="#">In addition to the CIA elements, there are additional tenets that form a basis for system security. The three operational tenets found in secure deployments are session management, exception management, and configuration management.

<li><a href="#">Session management is the set of activities employed to establish a communication channel between two parties, identifying each in a manner that allows future activity without renewed authentication.

<li><a href="#">Exceptions are the invocation of conditions that fall outside the normal sequence of operation. Whether by error or malicious action, exceptions are changes to normal processing and need to be managed. The handling of exceptions, referred to as exception handling, is an important consideration during software development. The bottom line is simple: either the system must handle the condition and recover, or it must fail and be recovered by separate action. Designing in exception handling makes a system more resilient, because exceptions will happen.

<li><a href="#">The proper configuration and provisioning of all of the components in a system is essential to the proper operation of the system. The design and operation of the elements to ensure the proper functional environment of a system is referred to as configuration management.

<li><a href="#">Host security and network-level security, have prevention as well as detection and response components. Rather than view these two approaches as independent solutions, a mature organization uses both in a complementary fashion.

<li><a href="#">Host security takes a granular view of security by focusing on protecting each computer and device individually instead of addressing protection of the network as a whole. When host security is used, each computer is relied upon to protect itself.

<li><a href="#">Host security is important and should always be addressed. Security, however, should not stop there, as host security is a complementary process to be combined with network security. If individual host computers have vulnerabilities embodied within them, then network security can provide another layer of protection that will, hopefully, stop any intruders who have gotten that far into the environment.

<li><a href="#">In some smaller environments, host security by itself may be an option, but as systems become connected into networks, security should include the actual network itself. In network security, an emphasis is placed on controlling access to internal computers from external entities. This control can be through devices such as routers, firewalls, authentication hardware and software, encryption, and intrusion detection systems (IDSs).

<li><a href="#">One of the most fundamental principles in security is least privilege. This concept is applicable to many physical environments as well as network and host security. Least privilege means that a subject (which may be a user, application, or process) should have only the necessary rights and privileges to perform its task with no additional permissions. Limiting an object's privileges limits the amount of harm that can be caused, thus limiting an organization's exposure to damage.

<li><a href="#">The principle of separation of privilege states that the protection mechanism should be constructed so that it uses more than one piece of information to make access decisions. Applying this principle to the people side of the security function results in the concept of separation of duties.

<li><a href="#">When applied to people's actions, separation of duties specifies that for any given task, more than one individual needs to be involved. The task is broken into different duties, each of which is accomplished by a separate individual. By implementing a task in this manner, no single individual can abuse the system for his or her own gain.

<li><a href="#">Fail-safe defaults is a concept that when something fails, it should do so to a safe state. One approach is that a protection mechanism should deny access by default, and grant access only when explicit permission exists. This is sometimes called default deny, and the common operational term for this approach is implicit deny.

<li><a href="#">If a particular situation is not covered by any of the other rules, the implicit deny approach states that access should not be granted. In other words, if no rule would allow access, then access should not be granted.

<li><a href="#">The terms security and complexity are often at odds with each other, because the more complex something is, the harder it is to understand, and you cannot truly secure something if you do not understand it. Another reason complexity is a problem within security is that it usually allows too many opportunities for something to go wrong.

<li><a href="#">The principle of economy of mechanism is described as always using simple solutions when available. An example of the principle concerns the number of services that you allow your system to run. Default installations of computer operating systems often leave many services running. The keep- it-simple principle tells us to eliminate or disable those services that we don't need. This is also a good idea from a security standpoint because it results in fewer applications that can be exploited and fewer services that the administrator is responsible for securing.

<li><a href="#">Complete mediation refers to the concept that each and every request should be verified. When permissions are verified the first time, and the result is cached for subsequent use, performance may be increased, but this also opens the door to permission errors.

<li><a href="#">The principle of open design holds that the protection of an object should not rely upon secrecy of the protection mechanism itself. This principle has been long proven in cryptographic circles, where hiding the algorithm ultimately fails and the true protection relies upon the secrecy and complexity of the keys.

<li><a href="#">Security through obscurity . In this case, security is considered effective if the environment and protection mechanisms are confusing or thought to be not generally known. Security through obscurity uses the approach of protecting something by hiding it. The idea is that if something is out of sight, it is out of mind. This approach, however, does not provide actual protection of the object. Security through obscurity may make someone work a little harder to accomplish a task, but it does not prevent anyone from eventually succeeding.

<li><a href="#">The principle of least common mechanism states that mechanisms used to access resources should be dedicated and not shared. Sharing of mechanisms allows a potential cross-over between channels resulting in a protection failure mode. The key is to provide a means of isolation between processes so information cannot flow between separate users unless specifically designed to do so.

<li><a href="#">Psychological acceptability refers to the users' acceptance of security measures. Users play a key role in the operation of a system, and if security measures are perceived to be an impediment to the work a user is responsible for, then a natural consequence may be that the user bypasses the control. Security professionals, particularly those designing the security systems, should not only be aware of this concept, but pay particular attention to how security controls will be viewed by workers in the context of their work responsibility, not with respect to security for its own sake.

<li><a href="#">Defense in depth is a principle that is characterized by the use of multiple, different defense mechanisms with a goal of improving the defensive response to an attack. Another term for defense in depth is layered security. Single points of failure represent just that, an opportunity to fail. By using multiple defenses that are different, with differing points of failure, a system becomes stronger.

<li><a href="#">Networks should utilize the same type of layered security architecture. There is no 100 percent secure system, and there is nothing that is foolproof, so a single specific protection mechanism should never be solely relied upon. The layers need to work together in a coordinated manner so that one does not impede another's functionality and introduce a security hole.

<li><a href="#">It is important to implement several different layers because if intruders succeed at one layer, you want to be able to stop them at the next. The redundancy of different protection layers assures that there is no one single point of failure pertaining to security.

<li><a href="#">Diversity of defense is a concept that complements the idea of various layers of security. It involves making different layers of security dissimilar so that even if attackers know how to get through a system that comprises one layer, they may not know how to get through a different type of layer that employs a different system for security. When applying the diversity-of-defense concept, you should set up these two firewalls to filter for different types of traffic and provide different types of restrictions.

<li><a href="#">Access control is the ability to control whether a subject (such as an individual or a process running on a computer system) can interact with an object (such as a file or hardware device).

<li><a href="#">Authentication is the process used to verify to the computer system or network that the individual is who they claim to be. Once the individual has verified their identity, access controls regulate what the individual can actually do on the system.

<li><a href="#">Access controls define what actions a user can perform or what objects a user can have access to. These controls assume that the identity of the user has been verified. In order to verify your identity, you can provide Something you know (knowledge factor) Something you have (possession factor) Something about you (something that you are)

<li><a href="#">Operating systems such as Windows and Linux allow administrators to organize users into groups, to create categories of users for which similar access policies can be established. A group policy defines for the group things such as the applicable operating system and application settings and permissions. Examples of groups commonly found include administrator, user, and guest.

<li><a href="#">The password policy should address the procedures used for selecting user passwords (specifying what is considered an acceptably complex password in the organization in terms of the character set and length), the frequency with which passwords must be changed, and how passwords will be distributed.

<li><a href="#">The U.S. military encouraged the development of the Bell-LaPadula security model to address data confidentiality in computer operating systems. This model is especially useful in designing multilevel security systems that implement the military's hierarchical security scheme, which includes levels of classification such as Unclassified, Confidential, Secret, and Top Secret.

<li><a href="#">A second confidentiality model, the Brewer-Nash security model, is one defined by controlling read and write access based on conflict of interest rules.

<li><a href="#">The Simple Security Rule, which states that no subject (such as a user or a program) can read information from an object (such as a file) with a security classification higher than that possessed by the subject itself. This rule is often referred to as the no-read-up rule.

<li><a href="#">the *-property (pronounced "star property" principle states that a subject can write to an object only if the target's security classification is greater than or equal to the object's security classification. The system is designed to make it impossible (hopefully) for data to be disclosed to those without the appropriate level to view it. This is what the system should protect against and is the reason for what is known as the no-write-down rule.

<li><a href="#">Not all environments are more concerned with confidentiality than integrity. In a financial institution, for example, viewing somebody's bank balance is an issue, but a greater issue would be the ability to actually modify that balance. In environments where integrity is more important, a different model than the Bell-LaPadula security model is needed.

<li><a href="#">The Brewer-Nash security model. In this model, information flows are modeled to prevent information from flowing between subjects and objects when a conflict of interest would occur.

<li><a href="#">In the Biba model, instead of security classifications, integrity levels are used. A principle of integrity levels is that data with a higher integrity level is believed to be more accurate or reliable than data with a lower integrity level.

<li><a href="#">Low-Water-Mark policy . This policy in many ways is the opposite of the *-property in that it prevents subjects from writing to objects of a higher integrity level. The policy also contains a second rule that states the integrity level of a subject will be lowered if it reads an object of a lower integrity level. The reason for this is that if the subject then uses data from that object, the highest the integrity level can be for a new object created from it is the same level of integrity of the original object.

<li><a href="#">While the Low-Water-Mark policy certainly prevents unauthorized modification of data, it has the unfortunate side effect of eventually lowering the integrity levels of all subjects to the lowest level on the system (unless the subject always views files with the same level of integrity). This is because of the second rule, which lowers the integrity level of the subject after accessing an object of a lower integrity level.

<li><a href="#">Biba's model in many respects is the opposite of the Bell-LaPadula model in that what it enforces are "no-read-down" and "no-write-up" policies. It also implements a third rule that prevents subjects from executing programs of a higher level.

<li><a href="#">Operational and Organizational Security

<li><a href="#">Policies are high-level, broad statements of what the organization wants to accomplish. They are made by management when laying out the organization's position on some issue. Procedures are the step-by-step instructions on how to implement policies in the organization. They describe exactly how employees are expected to act in a given situation or to accomplish a specific task.

<li><a href="#">Standards are mandatory elements regarding the implementation of a policy. They are accepted specifications that provide specific details on how a policy is to be enforced. Guidelines are recommendations relating to a policy. The key term in this case is recommendations-guidelines are not mandatory steps.

<li><a href="#">You have to evaluate the effectiveness of the security measures you have in place. This step may include a vulnerability assessment (an attempt to identify and prioritize the list of vulnerabilities within a system or network) and a penetration test (a method to check the security of a system by simulating an attack by a malicious individual) of your system to ensure the security is adequate.

<li><a href="#">The security policy is a high-level statement produced by senior management that outlines both what security means to the organization and the organization's goals for security. The main security policy can then be broken down into additional policies that cover specific topics.

<li><a href="#">An incident response policy and associated procedures should be developed to outline how the organization will prepare for security incidents and respond to them when they occur. The incident response policy should cover five phases: preparation, detection, containment and eradication, recovery, and follow-up actions.

<li><a href="#">Security awareness and training programs can enhance an organization's security posture in two direct ways. First, they teach personnel how to follow the correct set of actions to perform their duties in a secure manner. Second, they make personnel aware of the indicators and effects of social engineering attacks.

<li><a href="#">Training with respect to the information security policy, individual responsibilities, and expectations is something that requires periodic reinforcement through refresher training. The best defense against phishing and other social engineering attacks is an educated and aware body of employees. Continual refresher training about the topic of social engineering and specifics about current attack trends are needed to keep employees aware of and prepared for new trends in social engineering attacks.

<li><a href="#">Most experts will agree that the biggest danger to any organization does not come from external attacks but rather from the insider -a disgruntled employee or somebody else who has physical access to the facility. Consequently, every organization also needs security policies, procedures, and guidelines that cover physical security, and every security administrator should be concerned with these as well.

<li><a href="#">Physical security consists of all mechanisms used to ensure that physical access to the computer systems and networks is restricted to only authorized users. The most common physical access control device, which has been around in some form for centuries, is a lock. Newer locks replace the traditional key with a card that must be passed through a reader or placed against it. The individual may also have to provide a personal access code, thus making this form of access both a something-you- know and something-you-have method.

<li><a href="#">In addition to locks on doors, other common physical security devices include video surveillance and even simple access control logs (sign-in logs). Many organizations employ a guard to provide an extra level of examination of individuals who want to gain access to a facility. Other devices are limited to their designed function. A human guard can apply common sense to situations that might have been unexpected.

<li><a href="#">The Role of People in Security

<li><a href="#">A very basic fact that should be recognized is that technology alone will not solve the security problem. No matter how advanced the technology is, it will ultimately be deployed in an environment where humans exist. It is the human element that poses the biggest security challenge.

<li><a href="#">Social engineering is the process of convincing an authorized individual to provide confidential information or access to an unauthorized individual. It is a technique in which the attacker uses various deceptive practices to convince the targeted person to divulge information they normally would not divulge or to convince the target of the attack to do something they normally wouldn't do.

<li><a href="#">Social engineering is very successful for two general reasons. The first is the basic desire of most people to be helpful. The second reason that social engineering is successful is that individuals normally seek to avoid confrontation and trouble

<li><a href="#">Phishing (pronounced "fishing") is a type of social engineering in which an attacker attempts to obtain sensitive information from a user by masquerading as a trusted entity in an e-mail or instant message sent to a large group of often random users.

<li><a href="#">Despite the increasing media coverage concerning phishing attempts, some Internet users still fall for them, which results in attackers continuing to use this relatively cheap method to gain the information they are seeking.

<li><a href="#">Spear phishing is the term that has been created to refer to the special targeting of groups with something in common when launching a phishing attack. By targeting specific groups, the ratio of successful attacks (that is, the number of responses received) to the total number of e-mails or messages sent usually increases because a targeted attack will seem more plausible than a message sent to users randomly.

<li><a href="#">Shoulder surfing does not necessarily involve direct contact with the target, but instead involves the attacker directly observing the individual entering sensitive information on a form, keypad, or keyboard.

<li><a href="#">A slightly different approach to social engineering is called reverse social engineering. In this technique, the attacker hopes to convince the target to initiate the contact. The reason this attack may be successful is that, since the target is the one initiating the contact, attackers may not have to convince the target of their authenticity.

<li><a href="#">The password dilemma. The more difficult we make it for attackers to guess our passwords, and the more frequently we force password changes, the more difficult the passwords are for authorized users to remember and the more likely they are to write them down.

<li><a href="#">Tailgating or piggybacking is the simple tactic of following closely behind a person who has just used their own access card or PIN to gain physical access to a room or building. An attacker can thus gain access to the facility without having to know the access code or having to acquire an access card.

<li><a href="#">As a final note on user responsibilities, corporate security officers must cultivate an environment of trust in their office, as well as an understanding of the importance of security. If users feel that security personnel are only there to make their life difficult or to dredge up information that will result in an employee's termination, the atmosphere will quickly turn adversarial and be transformed into an "us versus them" situation.

<li><a href="#">Intrusion Detection Systems

<li><a href="#">An intrusion detection system (IDS) is a security system that detects inappropriate or malicious activity on a computer or network. The main purpose of an IDS is to identify suspicious or malicious activity, note activity that deviates from normal behavior, catalog and classify the activity, and, if possible, respond to the activity.

<li><a href="#">Host-based IDS (HIDS) Examines activity on an individual system, such as a mail server, web server, or individual PC. It is concerned only with an individual system and usually has no visibility into the activity on the network or systems around it.

<li><a href="#">Network-based IDS (NIDS) Examines activity on the network itself. It has visibility only into the traffic crossing the network link it is monitoring and typically has no idea of what is happening on individual systems.

<li><a href="#">Traffic collector (or sensor) Collects activity/events for the IDS to examine. On a HIDS, this could be log files, audit logs, or traffic coming to or leaving a specific system. On a NIDS, this is typically a mechanism for copying traffic off the network link-basically functioning as a sniffer. This component is often referred to as a sensor.

<li><a href="#">Analysis engine Examines the collected network traffic and compares it to known patterns of suspicious or malicious activity stored in the signature database. The analysis engine is the "brains" of the IDS.

<li><a href="#">Signature database A collection of patterns and definitions of known suspicious or malicious activity.

<li><a href="#">User interface and reporting Interfaces with the human element, providing alerts when appropriate and giving the user a means to interact with and operate the IDS.

<li><a href="#">In addition to being divided along the host and network lines, IDSs are often classified according to the detection model they use: anomaly or misuse.

<li><a href="#">An anomaly detection model is the more complicated of the two. In this model, the IDS must know what "normal" behavior on the host or network being protected really is. Once the "normal" behavior baseline is established, the IDS can then go to work identifying deviations from the norm, which are further scrutinized to determine whether or not that activity is malicious.

<li><a href="#">Unfortunately, most anomaly-based systems suffer from extremely high false positives, especially during the "break-in" period while the IDS is learning the network. On the other hand, an anomaly-based system is not restricted to a specific signature set and is far more likely to identify a new exploit or attack tool that would go unnoticed by a traditional IDS.

<li><a href="#">A misuse detection model is a little simpler to implement, and therefore it's the more popular of the two models. In a misuse detection model, the IDS looks for suspicious activity or activity that violates specific policies and then reacts as it has been programmed to do.

<li><a href="#">Some analysts break IDS models down even further into four categories depending on how the IDS operates and detects malicious traffic:

<li><a href="#">Behavior-based This model relies on a collected set of "normal behavior": what should happen on the network and is considered "normal" or "acceptable" traffic.

<li><a href="#">Signature-based This model relies on a predefined set of patterns (called signatures). The IDS has to know what behavior is considered "bad" ahead of time before it can identify and act upon suspicious or malicious traffic.

<li><a href="#">Anomaly-based This model is essentially the same as behavior-based. The IDS is first taught what "normal" traffic looks like and then looks for deviations to those "normal" patterns.

<li><a href="#">Heuristic This model uses artificial intelligence to detect intrusions and malicious traffic. A heuristic model is typically implemented through algorithms that help an IDS decide if a traffic pattern is malicious or not. This implementation of fuzzy logic allows this model to fall somewhere between signature-based and behavior-based models.

<li><a href="#">Signatures can be very simple or remarkably complicated, depending on the activity they are trying to highlight. In general, signatures can be divided into two main groups, depending on what the signature is looking for: content-based and context- based.

<li><a href="#">Content-based signatures are generally the simplest. They are designed to examine the content of such things as network packets or log entries. Content-based signatures are typically easy to build and look for simple things, such as a certain string of characters or a certain flag set in a TCP packet.

<li><a href="#">Context-based signatures are generally more complicated, as they are designed to match large patterns of activity and examine how certain types of activity fit into the other activities going on around them.

<li><a href="#">A NIDS has certain advantages that make it a good choice for certain situations:

<br>&#183; Providing IDS coverage requires fewer systems. With a few well-placed NIDS sensors, you can monitor all the network traffic going in and out of your organization.

<br>&#183; Deployment, maintenance, and upgrade costs are usually lower. The fewer systems that have to be managed and maintained to provide IDS coverage, the lower the cost to operate the IDS.

<br>&#183; A NIDS has visibility into all network traffic and can correlate attacks among multiple systems. Well-placed NIDS sensors can see the "big picture" when it comes to network-based attacks. The network sensors can tell you whether attacks are widespread and unorganized or focused and concentrated on specific systems.

<li><a href="#">A NIDS has certain disadvantages:

<br>&#183; It is ineffective when traffic is encrypted. When network traffic is encrypted from application to application or system to system, a NIDS sensor will not be able to examine that traffic. With the increasing popularity of encrypted traffic, this is becoming a bigger problem for effective IDS operations.

<br>&#183; It can't see traffic that does not cross it. The IDS sensor can examine only traffic crossing the network link it is monitoring. With most IDS sensors being placed on perimeter links, traffic traversing the internal network is never seen.

<br>&#183; It must be able to handle high volumes of traffic. As network speeds continue to increase, the network sensors must be able to keep pace and examine the traffic as quickly as it can pass the network.

<br>&#183; It doesn't know about activity on the hosts themselves. NIDSs focus on network traffic. Activity that occurs on the hosts themselves will not be seen by a NIDS.

<li><a href="#">Most NIDSs can be distinguished by how they examine the traffic and whether or not they interact with that traffic. On a passive system, the NIDS simply watches the traffic, analyzes it, and generates alarms.

<li><a href="#">An active NIDS contains all the same components and capabilities of the passive NIDS with one critical addition-the active NIDS can react to the traffic it is analyzing. These reactions can range from something simple, such as sending a TCP reset message to interrupt a potential attack and disconnect a session, to something complex, such as dynamically modifying firewall rules to reject all traffic from specific source IP addresses for the next 24 hours.

<li><a href="#">HIDSs can operate in real time, looking for activity as it occurs, or in batch mode, looking for activity on a periodic basis. Host-based systems are typically self-contained, but many of the newer commercial products have been designed to report to and be managed by a central system.

<li><a href="#">The analysis engine is perhaps the most important component of the HIDS, as it must decide what activity is "okay" and what activity is "bad." The analysis engine is a sophisticated decision and pattern-matching mechanism.

<li><a href="#">HIDSs have certain advantages that make them a good choice for certain situations:

<br>&#183; They can be very operating system-specific and have more detailed signatures. A HIDS can be very specifically designed to run on a certain operating system or to protect certain applications. This narrow focus lets developers concentrate on the specific things that affect the specific environment they are trying to protect.

<li><a href="#">They can reduce false-positive rates.

<br>&#183; They can examine data after it has been decrypted. With security concerns constantly on the rise, many developers are starting to encrypt their network communications. When designed and implemented in the right manner, a HIDS will be able to examine traffic that is unreadable to a network-based IDS.

<li><a href="#">They can be very application specific.

<br>&#183; They can determine whether or not an alarm may impact that specific system.

<br>&#183; HIDSs also have certain disadvantages that must be weighed in making the decision of whether to deploy this type of technology:

<br>&#183; The HIDS must have a process on every system you want to watch.

<br>&#183; The HIDS can have a high cost of ownership and maintenance. Unless some type of central console is used that allows you to maintain remote processes, administrators must maintain each HIDS process individually.

<li><a href="#">The HIDS uses local system resources.

<br>&#183; The HIDS has a very focused view and cannot relate to activity around it.

<br>&#183; The HIDS, if logging only locally, could be compromised or disabled.

<li><a href="#">The more advanced host- based offerings, which most vendors refer to as host-based intrusion prevention systems (HIPSs), combine the following elements into a single package:

<li><a href="#">Integrated system firewall The firewall component checks all network traffic passing into and out of the host. Users can set rules for what types of traffic they want to allow into or out of their system.

<li><a href="#">Behavioral- and signature-based IDS This hybrid approach uses signatures to match well-known attacks and generic patterns for catching "zero-day" or unknown attacks for which no signatures exist.

<li><a href="#">Application control This allows administrators to control how applications are used on the system and whether or not new applications can be installed.

<li><a href="#">Enterprise management Some host-based products are installed with an "agent" that allows them to be managed by and report back to a central server.

<li><a href="#">Malware detection and prevention Some HIDSs/HIPSs include scanning and prevention capabilities that address spyware, malware, rootkits, and other malicious software.

<li><a href="#">An intrusion prevention system (IPS) monitors network traffic for malicious or unwanted behavior and can block, reject, or redirect that traffic in real time. IPSs are merely expansions of existing IDS capabilities.

<li><a href="#">With rate-based monitoring, the IPS can watch the amount of traffic traversing the network. If the IPS sees too much traffic coming into or going out from a specific system or set of systems, the IPS can intervene and throttle down the traffic to a lower and more acceptable level.

<li><a href="#">A honeypot, sometimes called a digital sandbox, is an artificial environment where attackers can be contained and observed without putting real systems at risk. A good honeypot appears to an attacker to be a real network consisting of application servers, user systems, network traffic, and so on, but in most cases it's actually made up of one or a few systems running specialized software to simulate the user and network traffic common to most targeted networks.

<li><a href="#">Any time an attacker has been lured into probing or attacking the virtual network, the honeypot records the activity for later analysis: what the attacker does, which systems and applications she concentrates on, what tools are run, how long the attacker stays, and so on. All this information is collected and analyzed in the hopes that it will allow security personnel to better understand and protect against the threats to their systems.

<li><a href="#">Why aren't more businesses running honeypots? Quite simply, the time and cost are prohibitive. Honeypots take a lot of time and effort to manage and maintain, and even more effort to sort, analyze, and classify the traffic the honeypot collects.

<li><a href="#">A protocol analyzer (also known as a packet sniffer, network analyzer, or network sniffer) is a piece of software or an integrated software/hardware system that can capture and decode network traffic.

<li><a href="#">To accommodate protocol analyzers, IDS devices, and IPS devices, most switch manufacturers support port mirroring or a Switched Port Analyzer (SPAN) port. The network traffic is essentially copied (or mirrored) to a specific port, which can then support a protocol analyzer. Another option for traffic capture is to use a network tap, a hardware device that can be placed inline on a network connection and that will copy traffic passing through the tap to a second set of interfaces on the tap.

<li><a href="#">A port scanner is a tool designed to probe a system or systems for open ports. Its job is to probe for open (or listening) ports and report back to the user which ports are closed, which are filtered, and which are open.

<li><a href="#">By scanning a large number of ports over a large number of hosts, a port scanner can provide you (or an attacker) with a very good picture of what services are running on which hosts on your network.

<li><a href="#">Banner grabbing is a technique used to gather information from a service that publicizes information via a banner. Banners can be used for many things; for example, they can be used to identify services by type, version, and so forth, and they enable administrators to post information, including warnings, to users when they log in.

<li><a href="#">System Hardening

<li><a href="#">A good deal of effort must be put into protecting and securing the system before it is ever placed into service. The process of securing and preparing a system for the production environment is called hardening. Hardening systems, servers, workstations, networks, and applications is a process of defining the required uses and needs and aligning security controls to limit a system's desired functionality.

<li><a href="#">This process of establishing a system's security state is called baselining, and the resulting product is a security baseline that allows the system to run safely and securely. Uniform baselines are critical in large-scale operations because maintaining separate configurations and security levels for hundreds or thousands of systems is far too costly.

<li><a href="#">The operating system (OS) of a computer is the basic software that handles things such as input, output, display, memory management, and all the other highly detailed tasks required to support the user environment and associated applications.

<li><a href="#">A network operating system (NOS) is an operating system that includes additional functions and capabilities to assist in connecting computers and devices, such as printers, to a local area network (LAN).

<li><a href="#">For most modern operating systems, including Windows 2008, Solaris, and Linux, the terms operating system and network operating system are used interchangeably as they perform all the basic functions and provide enhanced capabilities for connecting to LANs.

<li><a href="#">The operating system itself is the foundation of system security. The operating system does this through the use of a security kernel. The security kernel is also called a reference monitor and is the component of the operating system that enforces the security policies of the operating system. The core of the OS is constructed so that all operations must pass through and be moderated by the security kernel, placing it in complete control over the enforcement of rules.

<li><a href="#">Host security is important and should always be addressed. Security, however, should not stop there, as host security is a complementary process to be combined with network security.

<li><a href="#">Once a server has been built and is ready to be placed into operation, the recording of hash values on all of its crucial files will provide valuable information later in case of a question concerning possible system integrity after a detected intrusion.

<li><a href="#">Removing methods of connecting additional devices to a workstation to move data-such as optical drives and USB ports-assists in controlling the movement of data into and out of the device.

<li><a href="#">You must meet several key requirements to ensure that the system hardening processes described in this section achieve their security goals. These are OS independent and should be a normal part of all system maintenance operations:

<br>&#183; The base installation of all OS and application software comes from a trusted source, and is verified as correct by using hash values.

<br>&#183; Machines are connected only to a completely trusted network during the installation, hardening, and update processes.

<br>&#183; The base installation includes all current service packs and updates for both the OS and applications.

<br>&#183; Current backup images are taken after hardening and updates to facilitate system restoration to a known state.

<li><a href="#">Here are some of the security capabilities introduced with Vista and continued in later versions of Windows:

<li><a href="#">User Account Control allows users to operate the system without requiring administrative privileges. This feature does help prevent users from "accidentally" making changes to their system configuration.

<li><a href="#">Windows Firewall includes an outbound filtering capability. Windows allows filtering of traffic coming into and leaving the system, which is useful for controlling things like peer-to-peer applications.

<li><a href="#">Vulnerability scanning can also help administrators identify common misconfigurations in account setup, patch levels, applications, and operating systems Most organizations look at vulnerability scanning as an ongoing process, as it is not enough to scan systems once and assume they will be secure from that point on.

<li><a href="#">Vendors typically follow a hierarchy for software updates:

<li><a href="#">Hotfix This is a term given to a (usually) small software update designed to address a specific problem, such as a buffer overflow in an application that exposes the system to attacks. Hotfixes are typically developed in reaction to a discovered problem and are produced and then released rather quickly. Hotfixes typically address critical, security-related issues and should be applied to the affected application or operating system as soon as possible.

<li><a href="#">Patch This term is usually applied to a more formal, larger software update that may address several or many software problems. Patches often contain enhancements or additional capabilities as well as fixes for known bugs. Patches are usually developed over a longer period of time.

<li><a href="#">Service pack This term is usually given to a large collection of patches and hotfixes rolled into a single, rather large package. Service packs are designed to bring a system up to the latest known good level all at once, rather than requiring the user or system administrator to download dozens or hundreds of updates separately.

<li><a href="#">Antivirus (AV) products attempt to identify, neutralize, or remove malicious programs, macros, and files. These products were initially designed to detect and remove computer viruses, though many of the antivirus products are now bundled with additional security products and features.

<li><a href="#">Most antivirus products combine the following approaches when scanning for viruses:

<li><a href="#">Signature-based scanning Much like an intrusion detection system (IDS), the antivirus products scan programs, files, macros, e-mails, and other data for known worms, viruses, and malware. The antivirus product contains a virus dictionary with thousands of known virus signatures that must be frequently updated, as new viruses are discovered daily. This approach will catch known viruses but is limited by the virus dictionary-what it does not know about it cannot catch.

<li><a href="#">Heuristic scanning (or analysis) Heuristic scanning does not rely on a virus dictionary. Instead, it looks for suspicious behavior-anything that does not fit into a "normal" pattern of behavior for the OS and applications running on the system being protected.

<li><a href="#">Heuristic scanning typically looks for commands or instructions that are not normally found in application programs, such as attempts to access a reserved memory register. A weight-based system rates every suspicious behavior based on the degree of threat associated with that behavior. A rule-based system compares activity to a set of rules meant to detect and identify malicious software.

<li><a href="#">As with IDS/IPS products, encryption and obfuscation pose a problem for antivirus products: anything that cannot be read cannot be matched against current virus dictionaries or activity patterns. To combat the use of encryption in malware and viruses, many heuristic scanners look for encryption and decryption loops.

<li><a href="#">Current antivirus products are highly configurable and most offerings will have the following capabilities:

<li><a href="#">Automated updates . Perhaps the most important feature of a good antivirus solution is its ability to keep itself up to date by automatically downloading the latest virus signatures on a frequent basis. This usually requires that the system be connected to the Internet in some fashion and that updates be performed on a daily (or more frequent) basis.

<li><a href="#">Automated scanning Most antivirus products allow for the scheduling of automated scans so that you can designate when the antivirus product will examine the local system for infected files. These automated scans can typically be scheduled for specific days and times, and the scanning parameters can be configured to specify what drives, directories, and types of files are scanned.

<li><a href="#">Media scanning . Removable media is still a common method for virus and malware propagation, and most antivirus products can be configured to automatically scan optical media, USB drives, memory sticks, or any other type of removable media as soon as they are connected to or accessed by the local system.

<li><a href="#">Manual scanning . Many antivirus products allow the user to scan drives, files, or directories (folders) "on demand."

<li><a href="#">E-mail scanning . E-mail is still a major method of virus and malware propagation. Many antivirus products give users the ability to scan both incoming and outgoing messages as well as any attachments.

<li><a href="#">Resolution When the antivirus product detects an infected file or application, it can typically perform one of several actions. The antivirus product may quarantine the file, making it inaccessible it may try to repair the file by removing the infection or offending code; or it may delete the infected file.

<li><a href="#">Antispam . products attempt to filter out that endless stream of junk e-mail so you don't have to. Some antispam products operate at the corporate level, filtering messages as they enter or leave designated mail servers. Other products operate at the host level, filtering messages as they come into your personal inbox. Most antispam products use similar techniques and approaches for filtering out spam:

<li><a href="#">Black listing . Several organizations maintain lists of servers or domains that generate or have generated spam. Most gateway- or server-level products can reference these black lists and automatically reject any mail coming from servers or domains on the black lists.

<li><a href="#">Header filtering . The antispam products look at the message headers to see if they are forged. E-mail headers typically contain information such as sender, receiver, servers used to transmit the message, and so on. Spammers often forge information in message headers in an attempt to hide where the message is really coming from.

<li><a href="#">Content filtering . The content of the message is examined for certain key words or phrases that are common to spam but rarely seen in legitimate e-mails ("get rich now" for example). Unfortunately, content filtering does occasionally flag legitimate messages as spam.

<li><a href="#">User-defined filtering. Most antispam products allow end users to develop their own filters, such as always allowing e-mail from a specific source even if it would normally be blocked by a content filter.

<li><a href="#">Trapping Some products will monitor unpublished e-mail addresses for incoming spam- anything sent to an unpublished and otherwise unused account is likely to be spam.

<li><a href="#">Egress filtering This technique scans mail as it leaves an organization to catch spam before it is sent to other organizations.

<li><a href="#">Spyware is the term used to define malware that is designed to steal information from the system, such as keystrokes, passwords, PINs, and keys. Antispyware helps protect your systems from the ever-increasing flood of malware that seeks to watch your keystrokes, steal your passwords, and report sensitive information back to attackers.

<li><a href="#">Applications can be controlled at the OS at the time of start via black listing or white listing. Black listing is essentially noting which applications should not be allowed to run on the machine. This is basically a permanent "ignore" or "call block" type capability. White listing is the exact opposite: it consists of a list of allowed applications. Each of these approaches has advantages and disadvantages. Black listing is difficult to use against dynamic threats, as the identification of a specific application can easily be avoided through minor changes.

<li><a href="#">Perhaps as important as OS and network hardening is application hardening-securing an application against local and Internet-based attacks. Hardening applications is fairly similar to hardening operating systems-you remove the functions or components you don't need, restrict access where you can, and make sure the application is kept up to date with patches.

<li><a href="#">Patch management is a disciplined approach to the acquisition, testing, and implementation of OS and application patches and requires a fair amount of resources to implement properly. Keeping track of patch availability is merely the first step; in many environments, patches must be analyzed and tested. Does the patch apply to the software you are running? Does the patch address a vulnerability or critical issue that must be addressed immediately? What is the impact of applying that patch or group of patches? Will it break something else if you apply this patch?

<li><a href="#">A vulnerability scanner is a program designed to probe hosts for weaknesses, misconfigurations, old versions of software, and so on. There are essentially three main categories of vulnerability scanners: network, host, and application.

<li><a href="#">A network vulnerability scanner probes a host or hosts for issues across their network connections. Typically a network scanner will either contain or use a port scanner to perform an initial assessment of the network to determine which hosts are alive and which services are open on those hosts. Each system and service is then probed.

<li><a href="#">Host vulnerability scanners are designed to run on a specific host and look for vulnerabilities and misconfigurations on that host. Host scanners tend to be more specialized because they're looking for issues associated with a specific operating system or set of operating systems. A good example of a host scanner is the Microsoft Baseline Security Analyzer (MBSA).

<li><a href="#">SCADA is an acronym for supervisory control and data acquisition, a system designed to control automated systems in cyber-physical environments. SCADA systems control manufacturing plants, traffic lights, refineries, energy networks, water plants, building automation and environmental controls, and a host of other systems. Where computers control a physical process directly, a SCADA system likely is involved. These systems frequently include a human machine interface (HMI), where an operator can exert a form of directive control over the operation of the system under control.

<li><a href="#">Many older SCADA systems were air-gapped from the corporate network; that is, they shared no direct network connections. This meant that data flows in and out were handled manually and took time to accomplish. Modern systems wished to remove this constraint and added direct network connections between the SCADA networks and the enterprise IT network. These connections increase the attack surface and the risk to the system, and the more they resemble an IT networked system, the greater the need for security functions.

<li><a href="#">Embedded system is the name given to a computer that is included as an integral part of a larger system. From computer peripherals like printers, to household devices like smart TVs and thermostats, to the car you drive, embedded systems are everywhere. Embedded systems are designed with a single control purpose in mind and have virtually no additional functionality, but this does not mean that they are free of risk or security concerns.

<li><a href="#">Because most embedded systems operate as isolated systems, the risks have not been significant. However, as capabilities have increased, and these devices have become networked together, the risks have increased significantly.

<li><a href="#">Network segmentation is the use of the network architecture to limit communication between devices. A variety of networking mechanisms can be used to limit access to devices at the network level. Logical network segmentation can be done via VLANs, MAC and IP address restrictions at routers and switches, firewall filtering, and access control mechanisms.

<li><a href="#">Types of Attacks and Malware

<li><a href="#">A computer system is attacked for one of two general reasons: it is specifically targeted by an attacker, or it is a target of opportunity. Targeted attacks are more difficult and take more time and effort than attacks on a target of opportunity. The latter type of attack simply relies on the fact that, with any piece of widely distributed software, somebody in the organization will not have patched the system as they should have.

<li><a href="#">Your first step to minimize possible attacks is to ensure that all patches for the operating system and applications are installed. The next step is to limit the services that are running on the system. Another step is to limit public disclosure of private information about your organization and its computing resources.

<li><a href="#">Malicious code, or malware, refers to software that has been designed for some nefarious purpose. Such software can be designed to cause damage to a system, such as by deleting all files, or it can be designed to create a backdoor in the system to grant access to unauthorized individuals.

<li><a href="#">A virus is a piece of malicious code that replicates by attaching itself to another piece of executable code. When the other executable code is run, the virus also executes and has the opportunity to infect other files and perform any other nefarious actions it was designed to do.

<li><a href="#">The first viruses created were of two types-boot sector viruses and program viruses. A boot sector virus infects the boot sector portion of either a floppy disk or a hard drive (years ago, not all computers had hard drives, and many booted from a floppy).

<li><a href="#">A second type of virus is the program virus, which attaches itself to executable files-typically files ending in .exe or .com on Windows-based systems. The virus is attached in such a way that it is executed before the program executes.

<li><a href="#">One method that has been used to detect this sort of virus before it has an opportunity to damage a system is to calculate checksums for commonly used programs or utilities. Should the checksum for an executable ever change, it is quite likely that it is due to a virus infection.

<li><a href="#">The proliferation of software that included macro-programming languages resulted in a new breed of virus-the macro virus . This type of virus is so common today that it is considered a security best practice to advise users never to open a document attached to an e-mail if it seems at all suspicious. Many organizations now routinely have their mail servers eliminate any attachments containing Visual Basic macros.

<li><a href="#">Two advances in virus writing have made it more difficult for antivirus software to detect viruses. These advances are the introduction of stealth virus techniques and polymorphic viruses. A stealthy virus employs techniques to help evade being detected by antivirus software that uses checksums or other techniques. Polymorphic viruses also attempt to evade detection, but they do so by changing the virus itself (the virus "evolves").

<li><a href="#">When a new form of malware/virus is discovered, antivirus companies and security researchers will decompile the program in an attempt to reverse-engineer its functionality. Much can be determined from reverse engineering, such as where the malware came from, how it works, how it communicates, how it spreads, and so forth. Armoring malware can make the process of determining this information much more difficult, if not impossible.

<li><a href="#">It was once easy to distinguish between a worm and a virus. Recently, with the introduction of new breeds of sophisticated malicious code, the distinction has blurred. Worms are pieces of code that attempt to penetrate networks and computer systems. Once a penetration occurs, the worm will create a new copy of itself on the penetrated system. The important distinction, however, is whether the code has to attach itself to something else (a virus) or if it can "survive" on its own (a worm).

<li><a href="#">The detection of malware by antimalware programs is primarily done through the use of a signature. Files are scanned for sections of code in the executable that act as markers, unique patterns of code that enable detection.

<li><a href="#">Malware writers are aware of this functionality and have adapted methods to defeat it. One of the primary means of avoiding detection by sensors is the use of polymorphic code, which is code that changes on a regular basis.

<li><a href="#">A Trojan horse, or simply Trojan, is a piece of software that appears to do one thing (and may, in fact, actually do that thing) but hides some other functionality. The challenge for the attacker is enticing the user to copy and run the program. This generally means that the program must be disguised as something that the user would want to run-a special utility or game, for example.

<li><a href="#">A rootkit is a form of malware that is specifically designed to modify the operation of the operating system in some fashion to facilitate non-standard functionality. The history of rootkits goes back to the beginning of the UNIX operating system, where they were sets of modified administrative tools. Originally designed to allow a program to take greater control over operating system function when it fails or becomes unresponsive, the technique has evolved and is used in a variety of ways.

<li><a href="#">Because of rootkits' invasive nature, and the fact that many aspects of rootkits are not easily detectable, most system administrators don't even attempt to clean up or remove a rootkit. It is far easier to use a previously captured clean system image and reimage the machine than to attempt to determine the depth and breadth of the damage and fix individual files.

<li><a href="#">A logic bomb is a piece of code that sits dormant for a period of time until some event invokes its malicious payload. An example of a logic bomb might be a program that is set to load and run automatically, and that periodically checks an organization's payroll or personnel database for a specific employee.

<li><a href="#">Spyware is software that "spies" on users, recording and reporting on their activities. It can record keystrokes (commonly called keylogging) when the user logs into specific websites. It can monitor how a user uses a specific piece of software (for example, monitor attempts to cheat at games).

<li><a href="#">Software that is supported by advertising is called adware. Adware comes in many different forms. With legitimate adware, the user is aware of the advertising and agrees to the arrangement in return for free use of the software. Adware can also refer to a form of malware, which is characterized by software that presents unwanted ads. These ads are sometimes an irritant, and at other times represent an actual security threat.

<li><a href="#">Hackers create armies of machines by installing malware agents on the machines, which then are called zombies. These collections of machines are called botnets. These zombies machines are used to conduct other attacks and to spread spam and other malware.

<li><a href="#">Backdoors were originally (and sometimes still are) nothing more than methods used by software developers to ensure that they could gain access to an application even if something were to happen in the future to prevent normal access methods.

<li><a href="#">The term backdoor is also, and more commonly, used to refer to programs that attackers install after gaining unauthorized access to a system to ensure that they can continue to have unrestricted access to the system, even if their initial access method is discovered and blocked.

<li><a href="#">Ransomware is a form of malware that performs some action and extracts ransom from a user. The most common form of ransomware is one that encrypts a key file or set of files, rendering a system unusable, or dataset unavailable. The attacker releases the information after being paid, typically in a nontraceable means such as bitcoin.

<li><a href="#">Early attack patterns were against the network, but most of today's attacks are aimed at the applications. This is primarily because this is where the objective of most attacks resides; in the infamous words of bank robber Willie Sutton, "because that's where the money is."

<li><a href="#">Application-level attacks take advantage of several facts associated with computer applications. First, most applications are large programs written by groups of programmers and, by their nature, have errors in design and coding that create vulnerabilities.

<li><a href="#">Attacks on specific protocols or services are attempts either to take advantage of a specific feature of the protocol or service or to use the protocol or service in a manner for which it was not intended.

<li><a href="#">A denial-of-service (DoS) attack is an attack designed to prevent a system or service from functioning normally. In a DoS attack, the attacker attempts to deny authorized users access either to specific information or to the computer system or network itself. This can be accomplished by crashing the system- taking it offline-or by sending so many requests that the machine is overwhelmed.

<li><a href="#">A SYN flood attack can be used to prevent service to a system temporarily in order to take advantage of a trusted relationship that exists between that system and another. In a SYN flooding attack, the attacker sends fake communication requests to the targeted system. Each of these requests will be answered by the target system, which then waits for the third part of the handshake. Since the requests are fake (a nonexistent IP address is used in the requests, so the target system is responding to a system that doesn't exist), the target will wait for responses that never come.

<li><a href="#">The number of connections a system can support is finite, so when more requests come in than can be processed, the system will soon be reserving all its connections for fake requests. At this point, any further requests are simply dropped (ignored), and legitimate users who want to connect to the target system will not be able to do so, because use of the system has been denied to them.

<li><a href="#">DoS attacks are conducted using a single attacking system. A DoS attack employing multiple attacking systems is known as a distributed denial-of-service (DDoS) attack. The goal of a DDoS attack is also to deny the use of or access to a specific service or system.

<li><a href="#">In a DDoS attack, service is denied by overwhelming the target with traffic from many different systems. A network of attack agents (sometimes called zombies) is created by the attacker, and upon receiving the attack command from the attacker, the attack agents commence sending a specific type of traffic against the target. If the attack network is large enough, even ordinary web traffic can quickly overwhelm the largest of sites.

<li><a href="#">Social engineering relies on lies and misrepresentation, which an attacker uses to trick an authorized user into providing information or access the attacker would not normally be entitled to. The attacker might, for example, contact a system administrator and pretend to be an authorized user, asking to have a password reset. Social engineering also applies to physical access. Simple techniques include impersonating pizza or flower delivery personnel to gain physical access to a facility.

<li><a href="#">Sniffing is when someone examines all the network traffic that passes their NIC, whether addressed for them or not. A network sniffer is a software or hardware device that is used to observe traffic as it passes through a network on shared broadcast media. The device can be used to view all traffic, or it can target a specific protocol, service, or even string of characters (looking for logins, for example). Some network sniffers are designed not just to observe all traffic but to modify traffic as well.

<li><a href="#">Network sniffers can be used by network administrators to monitor network performance. They can be used to perform traffic analysis, for example, to determine what type of traffic is most commonly carried on the network and to determine which segments are most active. They can also be used for network bandwidth analysis and to troubleshoot certain problems (such as duplicate MAC addresses).

<li><a href="#">Spoofing is nothing more than making data look like it has come from a different source. This is possible in TCP/IP because of the friendly assumptions behind the protocols. When the protocols were developed, it was assumed that individuals who had access to the network layer would be privileged users who could be trusted.

<li><a href="#">IP is designed to work so that the originators of any IP packet include their own IP address in the From portion of the packet. While this is the intent, nothing prevents a system from inserting a different address in the From portion of the packet. This is known as IP address spoofing.

<li><a href="#">Spoofing can also take advantage of a trusted relationship between two systems. If two systems are configured to accept the authentication accomplished by each other, an individual logged onto one system might not be forced to go through an authentication process again to access the other system. An attacker can take advantage of this arrangement by sending a packet to one system that appears to have come from a trusted system.

<li><a href="#">The attacker will often initially launch a DoS attack (such as a SYN flooding attack) to temporarily take out the spoofed system for the period of time that the attacker is exploiting the trusted relationship. Once the attack is completed, the DoS attack on the spoofed system would be terminated, and the system administrators, apart from having a temporarily nonresponsive system, might never notice that the attack occurred. Because of this type of attack, administrators are encouraged to strictly limit any trusted relationships between hosts.

<li><a href="#">A man-in-the-middle attack, as the name implies, generally occurs when attackers are able to place themselves in the middle of two other hosts that are communicating. Ideally, this is done by ensuring that all communication going to or from the target host is routed through the attacker's host (which can be accomplished if the attacker can compromise the router for the target host). The attacker can then observe all traffic before relaying it and can actually modify or block traffic.

<li><a href="#">There are numerous methods of instantiating a man-in-the-middle attack; one of the common methods is via session hijacking. Session hijacking can occur when information such as a cookie is stolen, allowing the attacker to impersonate the legitimate session. This attack can be as a result of a cross-site scripting attack, which tricks a user into executing code resulting in cookie theft.

<li><a href="#">A replay attack occurs when the attacker captures a portion of a communication between two parties and retransmits it at a later time. For example, an attacker might replay a series of commands and codes used in a financial transaction to cause the transaction to be conducted multiple times. Generally replay attacks are associated with attempts to circumvent authentication mechanisms, such as the capturing and reuse of a certificate or ticket.

<li><a href="#">The best way to prevent replay attacks is with encryption, cryptographic authentication, and time stamps. If a portion of the certificate or ticket includes a date/time stamp or an expiration date/time, and this portion is also encrypted as part of the ticket or certificate, replaying it at a later time will prove useless, since it will be rejected as having expired.

<li><a href="#">Phishing is the use of fraudulent e-mails or instant messages that appear to be genuine but are designed to trick users. The goal of a phishing attack is to obtain from the user information that can be used in an attack, such as login credentials or other critical information. Spear phishing is the term that has been created to refer to a phishing attack that targets a specific group with something in common.

<li><a href="#">The DNS system is used to convert a name into an IP address. There is not a single DNS system, but rather a hierarchy of DNS servers, from root servers on the backbone of the Internet, to copies at your ISP, your home router, and your local machine, each in the form of a DNS cache.

<li><a href="#">Looking at DNS as a complete system shows that there are hierarchical levels from the top (root server) down to the cache in an individual machine. DNS poisoning can occur at any of these levels, with the effect of the poisoning growing wider the higher up it occurs.

<li><a href="#">Because of the importance of integrity on DNS requests and responses, a project has begun to secure the DNS infrastructure using digital signing of DNS records. This project, initiated by the U.S. government and called Domain Name System Security Extensions (DNSSEC), works by digitally signing records. This is done by adding records to the DNS system, a key and a signature attesting to the validity of the key. With this information, requestors can be assured that the information they receive is correct.

<li><a href="#">An attacker can send messages, corrupt the ARP table, and cause packets to be misrouted. This form of attack is called ARP poisoning and results in malicious address redirection, This can allow a mechanism whereby an attacker can inject themselves into the middle of a conversation between two machines, a man-in- the-middle attack.

<li><a href="#">A brute-force attack on a password can take place at two levels: The attacker can use a password- cracking program to attempt to guess the password directly at a login prompt, or the attacker can first steal a password file, use a password-cracking program to compile a list of possible passwords based on the list of password hashes contained in the password file (offline), and then use that narrower list to attempt to guess the password at the login prompt. The first attack can be made more difficult if the account locks after a few failed login attempts. The second attack can be thwarted if the password file is securely maintained so that others cannot obtain a copy of it.

<li><a href="#">Pass the hash is a hacking technique where the attacker captures the hash used to authenticate a process. They can then use this hash, by injecting it into a process in place of the password. This is a highly technical attack, targeting the Windows authentication process, injecting a copy of the password hash directly into the system.

<li><a href="#">An attack that takes advantage of bugs or weaknesses in software is referred to as software exploitation. These bugs and weaknesses can be the result of poor design, poor testing, or poor coding practices. They can also result from what are sometimes called "features." An example of this might be a debugging feature, which when used during debugging might allow unauthenticated individuals to execute programs on a system.

<li><a href="#">A common weakness that has often been exploited is a buffer overflow, which occurs when a program is provided more data for input than it was designed to handle. This can result in a number of problems, including causing the program to abort or the system to crash. Under certain circumstances, the program can execute a command supplied by the attacker. Buffer overflows typically inherit the level of privilege enjoyed by the program being exploited. This is why programs that use root-level access are so dangerous when exploited with a buffer overflow, as the code that will execute does so at root-level access.

<li><a href="#">When user input is used without input validation, this gives an attacker the opportunity to craft input to create specific events to occur when the input is parsed and used by an application. SQL injection attacks involve the manipulation of input, resulting in a SQL statement that is different than intended by the designer. Command injection attacks can occur when input is used in a fashion that allows command-line manipulation, giving an attacker command-line access at the same privilege level as the application.

<li><a href="#">The advanced persistent threat (APT) is a method of attack that primarily focuses on stealth and continuous presence on a system. APT is a very advanced method, requiring a team to maintain access and typically involves high-value targets. APT typically involves specially crafted attack vectors, coupled with phishing or spear phishing for the initial entry. The techniques are employed to develop backdoors and multiple account access routes. The skill level of the attackers is typically exceedingly high and their aim is to completely own a system without being detected. APTs are the attack method of choice for nation-states and industrial espionage.

<li><a href="#">The following are indications of an APT attack:

<br>&#183; Off-hours activity. If logs demonstrate "normal" activity at times when your workers are at home, this is a sign of compromised accounts. Look for large numbers of occurrences, as APT attackers tend to use multiple accounts.

<br>&#183; Finding multiple backdoor Trojans/remote access Trojans. When security scans begin to find a lot of malware, this can be a sign of APTs.

<br>&#183; Finding unknown files. APTs tend to bundle exfiltration data and keep it in encrypted form before slowly siphoning it out. Discovery of large files of unknown origin can be these bundles.

<br>&#183; Finding spear phishing e-mails and pass-the-hash tools. These advanced attack methods are indications of an advanced adversary.

<br>&#183; Strange data flows. This is the most telltale sign. Finding unusual data flows, movement of data not in the normal course of business indicates leakage.

<li><a href="#">Remote access Trojans (RATs) are malware designed to enable remote access to a machine. This functionality is similar to remote desktop administration, but rather than being visible to a user, it is hidden in the system. RATs enable attackers to have a way back into a system.

<li><a href="#">You should conduct some form of security audit or assessment on a regular basis. Your organization might spend quite a bit on security, and it is important to measure how effective the efforts have been.

<li><a href="#">A powerful mechanism for detecting security incidents is the use of security logs. For logs to be effective, however, they require monitoring. Monitoring of event logs can provide information concerning the events that have been logged.

<li><a href="#">Here are some examples, but by no means a complete list, of items that should be audited on a regular basis:

<li><a href="#">User access . Administrators should review which users are accessing the systems, when they are doing so, what resources they are using, and so on.

<li><a href="#">User rights . When a user changes jobs or responsibilities, she will likely need to be assigned different access permissions; she may gain access to new resources and lose access to others. Storage Many organizations have policies governing what can be stored on "company" resources and how much space can be used by a given user or group.

<li><a href="#">Retention . In some organizations, how long a particular document or record is stored can be as important as what is being stored. A records retention policy helps to define what is stored, how it is stored, how long it is stored, and how it is disposed of when the time comes.

<li><a href="#">Firewall rules . Periodic audits of firewall rules are important to ensure the firewall is filtering traffic as desired and to help ensure that "temporary" rules do not end up as permanent additions to the rule set.

<li><a href="#">Incident Response

<li><a href="#">The system needs to be able to operate in a state of compromise, yet still achieve the desired security objectives. The mindset has to change from preventing intrusion and attack to preventing loss. A successful incident response effort requires two components, knowledge of one's own systems and knowledge of the adversary. Incident response is a term used to describe the steps an organization performs in response to any situation determined to be abnormal in the operation of a computer system.

<li><a href="#">An incident is any event in an information system or network where the results are different than normal. Incident response is not just an information security operation. Incident response is an effort that involves the entire business.

<li><a href="#">Two major elements play a role in determining the level of response. Information criticality is the primary determinant, and this comes from the data classification and the quantity of data involved. Information criticality is defined as the relative importance of specific information to the business. Information criticality is a key measure used in the prioritization of actions throughout the incident response process.

<li><a href="#">The second major element involves a business decision on how this incident plays into current business operations. A series of breaches, whether minor or not, indicates a pattern that can have public relations and regulatory issues.

<li><a href="#">Footprinting is the determination of the boundaries of a target space. There are numerous sources of information, including websites, DNS records, and IP address registrations. Understanding the boundaries assists an attacker in knowing what is in their target range and what isn't.

<li><a href="#">Scanning is the examination of machines to determine what operating systems, services, and vulnerabilities exist. The enumeration step is a listing of the systems and vulnerabilities to build an attack game plan.

<li><a href="#">The next step is to gain access to a higher-privilege account. From a higher-privilege account, the range of accessible activities is greater, including pilfering files, creating back doors so you can return, and covering your tracks by erasing logs.

<li><a href="#">Incident response is the set of actions security personnel perform in response to a wide range of triggering events. Incident response is a multistep process with several component elements. The first is organization preparation, followed by system preparation. An initial detection is followed by initial response, then isolation, investigation, recovery, and reporting.

<li><a href="#">Incident response is a key element of a security posture and must involve many different aspects of the business to properly respond. This is best built upon the foundation of a comprehensive incident response policy that details the roles and responsibilities of the organizational elements with respect to the process elements detailed in this chapter.

<li><a href="#">Incident response efforts begin before an incident occurs-that is, before "something goes wrong." Preparing for an incident is the first phase. The organization needs to establish the steps to be taken when an incident is discovered (or suspected); determine points of contact; train all employees and security professionals so they understand the steps to take and who to call; establish an incident response team; acquire the equipment necessary to detect, contain, and recover from an incident; establish the procedures and guidelines for the use of the equipment obtained; and train those who will use the equipment.

<li><a href="#">Understanding how access control is employed, including specifics across all systems, is key when determining who can do what-a common incident response question. Understanding the logging methodology and architecture will make incident response data retrieval easier.

<li><a href="#">One primary mitigation step is data minimization. Data minimization efforts can play a key role in both operational efficiency and security. One of the first rules associated with data is this: Don't keep what you don't need.

<li><a href="#">Data storage should be governed not by what you can store, but by the business need to store. What is not stored is not subject to breach, and minimizing storage to only what is supported by business need reduces risk and cost to the enterprise. One tool that can be used to assist in the selection of controls is a data classification scheme. Not all data is equally important, nor is it equally damaging in the event of loss.

<li><a href="#">An incident is defined as a situation that departs from normal, routine operations. Whether an incident is important or not is the first determination to be made as part of an incident response process.

<li><a href="#">When evidence accumulates, or in some cases when specific items such as security device logs indicate a potential incident, the next step is to escalate the situation to the incident response team.

<li><a href="#">A common technique is to develop a reporting template that can be supplied to an individual who suspects an incident, so that the necessary information is gathered in a timely manner.

<li><a href="#">Once an incident is discovered and characterized, the most important step in the incident response process involves the isolation of the problem. Many incidents can spread to other machines and expand the damage footprint if not contained by the incident response team.

<li><a href="#">One method of isolating a machine is through a quarantine process. Quarantine is a process of isolating an object from its surroundings, preventing normal access methods. A more extreme response is device removal. In the event that a machine becomes compromised, it is simply removed from production and replaced.

<li><a href="#">Having a knowledge base of previous incidents and the actions used is a valuable resource because it is in the context of the particular enterprise. These reports also allow a mechanism to close the loop with management over the incident and, most importantly, provide a roadmap of the actions that can be used in the future to prevent events of identical or similar nature.

<li><a href="#">The new standard of information security involves living in a state of compromise, where one should always expect that adversaries are active in their networks. It is unrealistic to expect that you can keep attackers out of your network.

<li><a href="#">Indicators of Compromise (IOCs) are artifacts left behind from computer intrusion activity. Detection of IOCs is a quick way to jumpstart a response element. One of the biggest challenges in incident response is getting on the trail of an attacker, and IOCs provide a means of getting on the trail.

<li><a href="#">Common Indicators of Compromise:

<br>&#183; Unusual outbound traffic. This probably is the clearest indicator that data is going where it shouldn't.

<br>&#183; Geographical irregularities. Communications going to countries in which no business ties exist is another key indicator that data is going where it shouldn't.

<br>&#183; Unusual login activity. Failed logins, login failures to nonexistent accounts, and so forth, indicate compromise.

<br>&#183; Anomalous usage patterns for privileged accounts. Changes in patterns of when administrators typically operate and what they typically access indicate compromise.

<br>&#183; Changes in database access patterns. This indicates hackers are searching for data, or reading it to collect large quantities.

<br>&#183; Automated web traffic. Timing can show some requests are scripts, not humans.

<br>&#183; Change in HTML response sizes. SQL injection can result in large HTML response sizes.

<br>&#183; Large numbers of requests for specific files. Numerous requests for specific files, such as join.php, may indicate automated attack patterns.

<br>&#183; Mismatched port to application traffic. Common method of attempting to hide activity. Unusual DNS requests. Command and control server traffic.

<br>&#183; Unusual Registry changes. Indications of changes to a system state. Unexpected patching. Some hackers/malware will patch to prevent other hackers from entering a target.

<br>&#183; Bundles of data/files in wrong place. Large aggregations of data, frequently encrypted, may be files being prepared for exfiltration.

<br>&#183; Changes to mobile device profiles. Mobile is the new perimeter, and changes may indicate malware.

<br>&#183; DDoS/DoS attacks. Denial of service is used as a tool to provide smokescreen or distraction.

<li><a href="#">Computer Forensics

<li><a href="#">The term forensics relates to the application of scientific knowledge to legal problems. Specifically, computer forensics involves the preservation, identification, documentation, and interpretation of computer data. In today's practice, computer forensics can be performed for three purposes:

<br>&#183; Investigating computer systems as related to a violation of law

<br>&#183; Investigating computer systems for compliance with an organization's policies

<br>&#183; Responding to a request for digital evidence (e-discovery)

<li><a href="#">Incident response is about corrective action-returning the system to a normal operational state-whereas forensics is about figuring out what happened.

<li><a href="#">Evidence consists of the documents, verbal statements, and material objects that are admissible in a court of law. Evidence is critical to convincing management, juries, judges, or other authorities that some kind of violation has occurred.

<li><a href="#">Bits of data are merely magnetic pulses on a disk or some other storage technology. Therefore, data must always be evaluated through some kind of "filter" rather than sensed directly. This is often of concern to auditors, because good auditing techniques recommend accessing the original data or a version that is as close as possible to the original data.

<li><a href="#">Evidence must be properly marked as it is collected so that it can be identified as a particular piece of evidence gathered at the scene. Properly label and store evidence, and make sure the labels can't be easily removed.

<li><a href="#">You should never examine a system with the utilities provided by that system. You should always use utilities that have been verified as correct and uncorrupted. Even better, use a forensic workstation, a computer system specifically designed to perform computer forensic activities. Being methodical is extremely important when identifying evidence. Do not collect evidence by yourself-have a second person who can serve as a witness to your actions.

<li><a href="#">Protect evidence from electromagnetic or mechanical damage. Ensure that evidence is not tampered with, damaged, or compromised by the procedures used during the investigation. This helps avoid potential liability problems later. Be especially cautious during transport of evidence to ensure custody of evidence is maintained and the evidence isn't damaged or tampered with.

<li><a href="#">In any legal proceeding, whether criminal or civil, the other party will always examine the storage conditions and, if less than perfect, place the burden on the person storing it to prove that it is still intact. This is just one reason why recording hash values upon collection is so important.

<li><a href="#">Evidence, once collected, must be properly controlled to prevent tampering. The chain of custody accounts for all persons who handled or had access to the evidence. The chain of custody shows who obtained the evidence, when and where it was obtained, where it was stored, and who had control or possession of the evidence for the entire time since the evidence was obtained.

<li><a href="#">If files, logs, and other information are going to be captured and used for evidence, you need to ensure that the data isn't modified. In most cases, a tool that implements a hashing algorithm to create message digests is used.

<li><a href="#">From a forensics perspective, Linux systems differ from Windows systems in three main ways:

<br>&#183; No registry. Program data is stored in scattered locations.
<br>&#183; Different file system. A multitude of different file systems are used.
<br>&#183; Plaintext abounds. Files and data tend to be in plaintext, which impacts searching.

<li><a href="#">Network forensics is the capture, recording, and analysis of network events in order to discover the source of network problems or security incidents. As a general-purpose tool, network forensics is nearly impossible because of the scale issues. But in specific situations, such as in front of high-value targets that have limited data movement, it can prove to be valuable. It can also be valuable in troubleshooting ongoing incidents and problems in the network.

</body>
</ul>
</div>
<script>
function myFunction() {
    var input, filter, ul, li, a, i, txtValue;
    input = document.getElementById("myInput");
    filter = input.value.toUpperCase();
    ul = document.getElementById("myUL");
    li = ul.getElementsByTagName("li");
    for (i = 0; i < li.length; i++) {
        a = li[i].getElementsByTagName("a")[0];
        txtValue = a.textContent || a.innerText;
        if (txtValue.toUpperCase().indexOf(filter) > -1) {
            li[i].style.display = "";
        } else {
            li[i].style.display = "none";
        }
    }
}
</script>
<script src="hilitor.js"></script>
<script>
var myHilitor = new Hilitor("content"); // id of the element to parse
// myHilitor.setBreakRegExp(new RegExp('[^\w -]+', "g")); // expanded to include spaces
myHilitor.apply();
</script>
<script>
  window.addEventListener("DOMContentLoaded", function(e) {
    var myHilitor2 = new Hilitor("playground");
    myHilitor2.setMatchType("left");
    document.getElementById("keywords").addEventListener("keyup", function(e) {
      myHilitor2.apply(this.value);
    }, false);
  }, false);
</script>

</html>
